[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Gustavo Frosi",
    "section": "",
    "text": "Github\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Email\n  \n  \n     CV.Lattes\n  \n  \n     ResearchGate\n  \n\n\n\nOlá! Sou Gustavo Frosi, formado em engenharia agronômica e mestre em ciência do solo. Atualmente, estou cursando doutorado na mesma área, concentrando minhas pesquisas e interesses de estudo na química e mineralogia do solo. Durante meu mestrado, investigamos o impacto da aplicação de resíduo industrial nos parâmetros químicos e mineralógicos do solo. No doutorado, meu foco é estabelecer a relação entre a mineralogia do solo como componente fundamental para a adubação de potássio e a capacidade de prever, por meio da mineralogia, o comportamento do nutriente e sua dinâmica no solo.\nAo longo da minha trajetória acadêmica, estabeleci um contato constante com dados e análises estatísticas, o que, ao longo dos anos, conduziu ao desenvolvimento de um verdadeiro interesse por essa área. Inegavelmente, ciência e dados caminham lado a lado.\n\nA estatística é a gramática da ciência - Karl Pearson\n\nEsta frase de Pearson descreve bem meu apego e dedicação ao estudo da análise de dados e estatística, motivando-me a avançar nos estudos nessa área.\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "recap.html",
    "href": "recap.html",
    "title": "Coisas legais!",
    "section": "",
    "text": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos\n\n\n\nR\n\n\nRegressão Linear\n\n\nEstatística\n\n\n\nAplicando a tecnologia de regressão linear para dados contínuos e/ou discretos\n\n\n\nGustavo Frosi\n\n\n22 de ago. de 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantos artigos eu preciso ter no currículo até o fim do doutorado em Ciência do Solo?\n\n\n\nR\n\n\nDoutorado\n\n\nDataViz\n\n\nggplot2\n\n\n\nAproximação da quantidade de artigos que alunos possuem publicados ao final do Doutorado\n\n\n\nGustavo Frosi\n\n\n15 de abr. de 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBananaBudget\n\n\n\nR\n\n\nDataViz\n\n\nggplot2\n\n\n\nAnálise exploratória de gastos do mercado com o R com foco em visualização.\n\n\n\nGustavo Frosi, Diogo Bolzan\n\n\n15 de fev. de 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeb scraping Nota Fiscal Gaúcha\n\n\n\nR\n\n\npython\n\n\nWeb scraping\n\n\n\nAutomatizando o download de notas para consumidor final e a extração de dados.\n\n\n\nGustavo Frosi\n\n\n6 de fev. de 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrabalhos - XXIII CLACS | XXXVIII CBCS\n\n\n\nR\n\n\nSolos\n\n\n\nExplorando a relação dos trabalhos publicados e apresentados no XXIII CLACS | XXXVIII CBCS.\n\n\n\nGustavo Frosi, Dayana Eckert\n\n\n17 de dez. de 2023\n\n\n\n\n\n\n\n\nNenhum item correspondente\n\n\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "Projetos/index.html",
    "href": "Projetos/index.html",
    "title": "Gustavo Frosi",
    "section": "",
    "text": "Em construção…"
  },
  {
    "objectID": "CV/index.html",
    "href": "CV/index.html",
    "title": "Gustavo Frosi",
    "section": "",
    "text": "Página em construção\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "recap/2023-12-17 CBCS 2023/index.html",
    "href": "recap/2023-12-17 CBCS 2023/index.html",
    "title": "Trabalhos - XXIII CLACS | XXXVIII CBCS",
    "section": "",
    "text": "O Congresso Brasileiro de Ciência do Solo (CBCS) é um evento técnico-científico que ocorre a cada dois anos (anos ímpares). O objetivo deste evento é reunir alunos, professores, pesquisadores e profissionais das áreas afins para a troca de conhecimento e discussão sobre as futuras perspectivas da ciência do solo.\nEsse ano o XXXVIII CBCS ocorreu em Florianopolis – SC, concomitante a ele ocorreu o XXIII Congresso Latino-Americado de Ciência do solo (CLACS). O evento em conjunto foi chamado de SOLOS FLORIPA 2023, com organização das sociedades Latino-americana (SLCS) e Brasileira (SBCS) da Ciência do Solo e realização da Empresa de Pesquisa Agropecuária e Extensão Rural de Santa Catarina (Epagri).\nUma das características mais importante do congresso é a possibilidade de os “pesquisadores” apresentarem trabalhos técnico-científicos sobre seus respectivos objetos de estudo. Diante disso, surge a dúvida em saber quais as áreas/subáreas teve as maiores quantidades de trabalhos apresentados e talvez entender o foco das pesquisas em Ciência do Solo na atualidade. Para sanar essa dúvida (pelo menos parcialmente) apresento nesse post uma forma de retirar os dados do site do congresso e realizar uma apresentação gráfica sobre os trabalhos. Para isso utilizo a linguagem de programação R.\nPara mais informações acesse o site: https://solosfloripa2023.com.br/solos2023"
  },
  {
    "objectID": "recap/2023-12-17 CBCS 2023/index.html#dados",
    "href": "recap/2023-12-17 CBCS 2023/index.html#dados",
    "title": "Trabalhos - XXIII CLACS | XXXVIII CBCS",
    "section": "Dados",
    "text": "Dados\nOs dados do número de trabalhos está na página de Trabalho Aprovados no site. A captura dos dados foi realizada com o endereço eletrônico da página. Um avaliação prévia de como se conportava a página e como os dados aparaciam foi realizada.\n\n\nCódigo\nprimeira_parte &lt;- \"https://solosfloripa2023.com.br/evento/solos2023/trabalhosaprovados?titulo=&autor=&t1area_id=\"\n\nid &lt;- c(1, 2, 3, 8, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16)\n\nsegunda_parte &lt;- \"&modeloformaapresentacaofinal_id=&btBuscar=Buscar\"\n\n\nUm loop foi realizado para remover os dados de cada uma das áreas e subareas.\n\n\nCódigo\ndf &lt;- as.data.frame(x = 1:length(id))\nfor (i in 1:16) {\n  dados &lt;- httr::GET(paste0(primeira_parte, id[i], segunda_parte))\n  get_content &lt;- httr::content(dados)\n\n  raw_table &lt;- get_content |&gt;\n    rvest::html_nodes(\".container-fluid\")\n\n  df[i, ] &lt;-\n    raw_table[[3]] |&gt;\n    rvest::html_text() |&gt;\n    strsplit(\"\\n\") |&gt;\n    unlist() |&gt;\n    enframe(name = NULL, value = \"linha\") |&gt;\n    dplyr::filter(stringr::str_detect(linha, pattern = \".*registro\"))\n}\n\n\nAlém de captar as iformações, foi realizado um processamento e manipulação para organizar os dados.\n\n\nCódigo\ndivi &lt;- raw_table[[3]] |&gt;\n  rvest::html_text() |&gt;\n  strsplit(\"\\n\") |&gt;\n  unlist() |&gt;\n  enframe(name = NULL, value = \"linha\") |&gt;\n  dplyr::filter(stringr::str_detect(linha, pattern = \" TODASDivisã\")) |&gt;\n  str_split(pattern = \"Di\", simplify = T) |&gt;\n  as.data.frame() |&gt;\n  pivot_longer(cols = 2:17, names_to = \"Divi\", values_to = \"nome\") |&gt;\n  filter(Divi != \"V1\") |&gt;\n  mutate(di = \"Di\") |&gt;\n  transmute(Divi = paste(di, nome, sep = \"\"))\n\n\nd_final &lt;- cbind(divi, df)\n\ndados.ok &lt;- d_final |&gt;\n  mutate(\n    partici = str_extract(`1:length(id)`,\n      pattern = \"[:digit:]{1,}\"\n    ),\n    partici = as.numeric(partici)\n  ) \n\n\ncomi &lt;- str_split(d_final$Divi, \":\")\ndata_separado &lt;- data.frame(do.call(rbind, comi))\n\ndf_ok &lt;- cbind(data_separado, dados.ok)\n\ndf_ok &lt;- df_ok |&gt; mutate(remover = str_sub(df_ok$X2, start = 16, end = 90))\n\nfont_add(\"Didot\", \"GFS_Didot/GFSDidot-Regular.ttf\")\n\nshowtext_auto()"
  },
  {
    "objectID": "recap/2023-12-17 CBCS 2023/index.html#trabalhos-dentro-de-cada-divisão",
    "href": "recap/2023-12-17 CBCS 2023/index.html#trabalhos-dentro-de-cada-divisão",
    "title": "Trabalhos - XXIII CLACS | XXXVIII CBCS",
    "section": "Trabalhos dentro de cada divisão",
    "text": "Trabalhos dentro de cada divisão\n\nDivisão 1Divisão 2Divisão 3Divisão 4\n\n\n\n\nCódigo\ndf_ok |&gt;\n  filter(X1 == \"Divisão 1 – Solo no espaço e no tempo\") |&gt;\n  ggplot(aes(y = partici, x = fct_reorder(remover, partici))) +\n  coord_flip() +\n  geom_col(fill = \"#ef8118\", col = \"#bc6a1d\") +\n  # facet_wrap(~X1, scales = \"free\") +\n  labs(\n    x = NULL, y = \"Nº de trabalhos\",\n    title = 'Resumos no &lt;span style = \"color:#ef8118\"&gt; XXIII CLACS | XXXVIII CBCS &lt;/span&gt;',\n    subtitle = \"Divisão 1 – Solo no espaço e no tempo\"\n  ) +\n  geom_text(aes(label = partici), nudge_y = -2, col = \"black\", size = 5) +\n  theme_minimal(24) +\n  theme(\n    text = element_text(family = \"Didot\"),\n    plot.title = ggtext::element_markdown()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCódigo\ndf_ok |&gt;\n  filter(X1 == \"Divisão 2 – Processos e Propriedades do Solo\") |&gt;\n  ggplot(aes(y = partici, x = fct_reorder(remover, partici))) +\n  coord_flip() +\n  geom_col(fill = \"#ef8118\", col = \"#bc6a1d\") +\n  # facet_wrap(~X1, scales = \"free\") +\n  labs(\n    x = NULL, y = \"Nº de trabalhos\",\n    title = 'Resumos no &lt;span style = \"color:#ef8118\"&gt; XXIII CLACS | XXXVIII CBCS &lt;/span&gt;',\n    subtitle = \"Divisão 2 – Processos e Propriedades do Solo\"\n  ) +\n  geom_text(aes(label = partici), nudge_y = -4, col = \"black\", size = 6) +\n  theme_minimal(24) +\n  theme(\n    text = element_text(family = \"Didot\"),\n     plot.title  = element_markdown()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCódigo\ndf_ok |&gt;\n  filter(X1 == \"Divisão 3 – Uso e Manejo do Solo\") |&gt; \nmutate(remover = factor(remover, levels = c(\n  \" Fertilidade do Solo e Nutrição de Plantas\",\n  \" Corretivos e Fertilizantes\", \n  \" Manejo e Conservação do Solo e da Água\", \n  \" Planejamento do Uso da Terra\", \n  \" Poluição, Remediação do Solo e Recuperação de Áreas Degradadas\"\n), labels = c(\n  \"Fertilidade do Solo e \\n Nutrição de Plantas\",\n  \"Corretivos e Fertilizantes\",\n  \"Manejo e Conservação \\n do Solo e da Água\",\n  \"Planejamento do Uso da Terra\",\n  \"Poluição, Remediação do Solo e \\n Recuperação de Áreas Degradadas\"\n))) |&gt;\n  ggplot(aes(y = partici, x = fct_reorder(remover, partici))) +\n  coord_flip() +\n  geom_col(fill = \"#ef8118\", col = \"#bc6a1d\") +\n  # facet_wrap(~X1, scales = \"free\") +\n  labs(\n    x = NULL, y = \"Nº de trabalhos\",\n    title = 'Resumos no &lt;span style = \"color:#ef8118\"&gt; XXIII CLACS | XXXVIII CBCS &lt;/span&gt;',\n    subtitle = \"Divisão 3 – Uso e Manejo do Solo\"\n  ) +\n  geom_text(aes(label = partici), nudge_y = -13, col = \"black\", size = 6) +\n  theme_minimal(24) +\n  theme(\n    text = element_text(family = \"Didot\"),\n    plot.title = element_markdown()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCódigo\ndf_ok |&gt;\n  filter(X1 == \"Divisão 4 - Solo, Ambiente e Sociedade\") |&gt;\n  mutate(remover = factor(remover, labels = c(\n    \"Educação em Solos e \\n Percepção Pública do Solo\",\n    \"História, Epistemologia e \\n Sociologia da Ciência\",\n    \"Solos e Segurança Alimentar\"\n  ))) |&gt;\n  ggplot(aes(y = partici, x = fct_reorder(remover, partici))) +\n  coord_flip() +\n  geom_col(fill = \"#ef8118\", col = \"#bc6a1d\") +\n  # facet_wrap(~X1, scales = \"free\") +\n  labs(\n    x = NULL, y = \"Nº de trabalhos\",\n    title = 'Resumos no &lt;span style = \"color:#ef8118\"&gt; XXIII CLACS | XXXVIII CBCS &lt;/span&gt;',\n    subtitle = \"Divisão 4 - Solo, Ambiente e Sociedade\"\n  ) +\n  geom_text(aes(label = partici), nudge_y = -2, col = \"black\", size = 6) +\n  theme_minimal(24) +\n  theme(\n    text = element_text(family = \"Didot\"),\n     plot.title  = element_markdown()\n  )"
  },
  {
    "objectID": "recap/2023-12-17 CBCS 2023/index.html#trabalhos-entre-as-divisões",
    "href": "recap/2023-12-17 CBCS 2023/index.html#trabalhos-entre-as-divisões",
    "title": "Trabalhos - XXIII CLACS | XXXVIII CBCS",
    "section": "Trabalhos entre as divisões",
    "text": "Trabalhos entre as divisões\nDe forma geral, observa-se que a maioria dos trabalhos submetidos e apresentados no evento pertence à divisão científica 3 – Uso e Manejo do Solo, totalizando 829 trabalhos. Em contrapartida, a divisão 4 – Solo, Ambiente e Sociedade apresentou o menor número de trabalhos, com apenas 58.\nNão podemos afirmar que esses números representam a totalidade dos trabalhos realizados em cada área, mas eles podem fornecer uma amostra do cenário atual das pesquisas em Ciência do Solo.\nA disparidade nos estudos entre as áreas da Ciência do Solo levanta questionamentos sobre a direção da pesquisa nesse campo. É pertinente refletir se nossas investigações estão se aproximando das necessidades da sociedade e se estão verdadeiramente cumprindo o papel que a Ciência deve desempenhar.\nEssa discrepância nos números sugere a importância de uma análise mais aprofundada sobre os temas predominantes e as lacunas existentes na pesquisa em Ciência do Solo. Incentivar a discussão dentro da comunidade científica pode ser valioso para garantir que as pesquisas estejam alinhadas com as demandas sociais e ambientais atuais.\n\n\nCódigo\ndf_ok |&gt;\n  group_by(X1) |&gt;\n  summarise(soma = sum(partici)) |&gt;\n  mutate(\n    X1 = factor(X1, labels = c(\n      \"Divisão 1 – Solo no \\n espaço e no tempo\",\n      \"Divisão 2 – Processos e \\n  Propriedades do Solo\",\n      \"Divisão 3 – Uso e \\n Manejo do Solo\",\n      \"Divisão 4 - Solo, \\n Ambiente e Sociedade\"\n    )),\n    total = sum(soma)\n  ) |&gt;\n  ggplot(aes(y = soma, x = fct_reorder(X1, soma))) +\n  coord_flip() +\n  geom_col(fill = \"#ef8118\", col = \"#bc6a1d\") +\n  # facet_wrap(~X1, scales = \"free\") +\n  labs(\n    x = NULL, y = \"Nº de trabalhos\",\n    title = 'Resumos no &lt;span style = \"color:#ef8118\"&gt; XXIII CLACS | XXXVIII CBCS &lt;/span&gt;',\n    subtitle = \"Total por divisão\"\n  ) +\n  geom_text(aes(label = soma), nudge_y = -32, col = \"black\", size = 6) +\n  theme_minimal(24) +\n  theme(\n    text = element_text(family = \"Didot\"),\n    plot.title = element_markdown()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nOs códigos apresentados foram produzidos sem critérios de qualidade. Melhorias ainda podem ser feitas."
  },
  {
    "objectID": "recap/2024-02-05 webscraping python/index.html",
    "href": "recap/2024-02-05 webscraping python/index.html",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "",
    "text": "Você já se perguntou quanto gastou no mercado? E quais os itens que mais comprou? Bom, se você disse que não, acho melhor começar a pensar, e se você disse que sim, mas não sabe como fazer para buscar esses dados, eu tenho uma boa notícia!\nNeste texto, descrevo como utilizei o Python na criação de um código que automatizou o download das minhas notas fiscais pessoais (NFC: Nota Fiscal de Consumidor). Deixo claro que o código é destinado ao uso pessoal e doméstico. Minha intenção é apenas o controle de gastos financeiros (e outras brincadeiras com dados).\nO exemplo que utilizo aqui é para o site Nota Fiscal Gaúcha e serve apenas para quem utiliza o “benefício”. Fica obvio que é necessário colocar o CPF em todas as compras né.\nAntes de começar a codificar, é necessário baixar o webdriver, uma ferramenta para testes de automação que oferece uma série de recursos para utilizar o navegador. O webdriver a ser baixado depende do navegador que você utiliza e da versão instalada. No meu caso, vou ensinar com o navegador da Google, o Google Chrome na versão 121.0.6167.140.\nPara fazer o download do webdriver, basta acessar o link\nDepois de baixado, é necessário colar o webdriver na pasta onde está o executável do Python. No meu caso, como utilizo o Anaconda, colei no diretório do Anaconda, o mesmo onde fica o Python.\nAgora sim! Com isso, já é possível começar a escrever códigos."
  },
  {
    "objectID": "recap/2024-02-05 webscraping python/index.html#manipulação-de-banco-baixado",
    "href": "recap/2024-02-05 webscraping python/index.html#manipulação-de-banco-baixado",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "Manipulação de banco baixado",
    "text": "Manipulação de banco baixado\nDa planilha baixada do site, apenas a coluna que contém a chave de acesso da nota fiscal é relevante. Realizei uma pequena manipulação na planilha, removendo os espaços da coluna da chave de acesso, e a salvei como arquivo CSV.\n\n\nCódigo\nlibrary(tidyverse)\n\n\ndados &lt;- readxl::read_excel(\"notas/Nota Fiscal Gaúcha.xlsx\") |&gt;\n  janitor::clean_names() |&gt;\n  mutate(chave = chave_de_acesso |&gt; str_remove_all(pattern = \"\\\\s\")) |&gt;\n  select(chave)\n\n\n\nwrite.csv(x = dados, file = \"notas/para_auto.csv\")\n\n\n\n\n\n\n\n\nNota\n\n\n\nOs códigos apresentados foram produzidos sem critérios de qualidade. Melhorias ainda podem ser feitas."
  },
  {
    "objectID": "recap/2024-02-05 webscraping python/index.html#ajustando-a-planilha-com-a-chave-de-acesso",
    "href": "recap/2024-02-05 webscraping python/index.html#ajustando-a-planilha-com-a-chave-de-acesso",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "Ajustando a planilha com a chave de acesso",
    "text": "Ajustando a planilha com a chave de acesso\nDa planilha baixada do site, apenas a coluna que contém a chave de acesso da nota fiscal é relevante. Realizei uma pequena manipulação na planilha, removendo os espaços da coluna da chave de acesso, e a salvei como arquivo CSV.\n\nlibrary(tidyverse)\n\n\ndados &lt;- readxl::read_excel(\"Nota Fiscal Gaúcha.xlsx\") |&gt;\n  janitor::clean_names() |&gt;\n  mutate(chave = chave_de_acesso |&gt; str_remove_all(pattern = \"\\\\s\")) |&gt;\n  select(chave)\n\nwrite.csv(x = dados, file = \"notas/para_auto.csv\")\n\n\n\n\n\n\n\nNota\n\n\n\nOs códigos apresentados foram produzidos sem critérios de qualidade. Melhorias ainda podem ser feitas."
  },
  {
    "objectID": "recap/2024-02-05 webscraping python/index.html#ajuste-da-chave-de-acesso",
    "href": "recap/2024-02-05 webscraping python/index.html#ajuste-da-chave-de-acesso",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "Ajuste da chave de acesso",
    "text": "Ajuste da chave de acesso\nDa planilha baixada do site, apenas a coluna que contém a chave de acesso da nota fiscal é relevante. Realizei uma pequena manipulação na planilha, removendo os espaços da coluna da chave de acesso, e a salvei como arquivo CSV.\n\n\n\n\n\n\nNota\n\n\n\nCódigos em R\n\n\n\nlibrary(tidyverse)\n\ndados &lt;- readxl::read_excel(\"Nota Fiscal Gaúcha.xlsx\") |&gt;\n  janitor::clean_names() |&gt;\n  mutate(chave = chave_de_acesso |&gt; str_remove_all(pattern = \"\\\\s\")) |&gt;\n  select(chave)\n\nwrite.csv(x = dados, file = \"notas/para_auto.csv\")"
  },
  {
    "objectID": "recap/2024-02-05 webscraping python/index.html#encontrando-os-pontos-de-click",
    "href": "recap/2024-02-05 webscraping python/index.html#encontrando-os-pontos-de-click",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "Encontrando os pontos de click",
    "text": "Encontrando os pontos de click\n\n\n\n\n\n\nNota\n\n\n\nAgora serão apenas códigos em python\n\n\nO procedimento que apresento aqui é baseado em um algoritmo que controla o mouse do computador, realizando cliques e movimentos programados. Como é de se esperar, é necessário fornecer as coordenadas para guiar os movimentos. Essa é uma tarefa manual, porém, é realizada apenas uma vez e se aplica a todas as notas (baixei mais de 200 notas).\nUtilizei o MouseInfo para identificar os pontos. Após abrir o console do python (melhor fazer pelo console) é só dar os seguintes comandos:\n\nfrom mouseinfo import mouseInfo\n\nmouseInfo()\n\nBasta realizar um teste com o MouseInfo aberto. Abra o site onde as notas serão baixadas e identifique os pontos onde será necessário realizar os cliques.\n\n\n\n\n\n\nNota\n\n\n\nOs códigos apresentados foram produzidos sem critérios de qualidade. Melhorias ainda podem ser feitas."
  },
  {
    "objectID": "recap/2024-02-05 webscraping python/index.html#encontrando-os-pontos-de-clique",
    "href": "recap/2024-02-05 webscraping python/index.html#encontrando-os-pontos-de-clique",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "Encontrando os pontos de clique",
    "text": "Encontrando os pontos de clique\n\n\n\n\n\n\nNota\n\n\n\nAgora serão apenas códigos em python\n\n\nO procedimento que apresento aqui é baseado em um algoritmo que controla o mouse do computador, realizando cliques e movimentos programados. Como é de se esperar, é necessário fornecer as coordenadas para guiar os movimentos. Essa é uma tarefa manual, porém, é realizada apenas uma vez e se aplica a todas as notas (baixei mais de 200 notas).\nUtilizei o MouseInfo para identificar os pontos. Após abrir o console do python (melhor fazer pelo console) é só dar os seguintes comandos:\n\nfrom mouseinfo import mouseInfo\n\nmouseInfo()\n\nO vídeo abaixo demonstra o funcionamento do MouseInfo, exibindo as marcações das coordenadas x e y à medida que o mouse é movido.\nVideo\nPara encontar os ponto certo basta realizar um teste com o MouseInfo aberto. Abra o site onde as notas serão baixadas e identifique os pontos onde será necessário realizar os cliques. O atalho F6 pode ser utilizado no MouseInfo para marcar as pontos x e y. Siga os passo:\n1º Passo: Clique em avançar e depois em imprimir Figura 2\n\n\n\n\n\n\n\n\n\n2º Passo: Clique em imprimir na parte do pdf Figura 3\n\n\n\n\n\n\n\n\n\n3º Passo: Clique em salvar Figura 4\n\n\n\n\n\n\n\n\n\nPor padrão, o Windows salva na pasta de downloads, mas é possível alterar para a pasta desejada. Basta encontrar o ponto de clique e realizar a mudança de destino."
  },
  {
    "objectID": "recap/2024-02-05 webscraping python/index.html#resultado",
    "href": "recap/2024-02-05 webscraping python/index.html#resultado",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "Resultado",
    "text": "Resultado\nO vídeo exibe o “robô” em ação, realizando a impressão e salvando automaticamente cada uma das notas. Na minha análise, as 205 notas que obtive foram processadas em quase 21 minutos, o que equivale a ~6 segundos por nota (Um computador melhor fará em menos tempo). E você, ocupado com diversas tarefas, conseguiria realizar isso de maneira mais rápida? Mesmo ao atingir a nota de número 100 e perceber que ainda falta mais da metade. Se acha que não, a resposta para isso é simples: programação!\nVideo\nE agora, o que fazer com essas notas? Começar a extrair os dados manualmente? Pagar alguém para fazer? Excluir do computador e dar um ponto final?\nA resposta óbvia é sim, dar um ponto final e excluir. No entanto, se ainda assim você deseja extrair informações dos seus dados, eu aconselho a conferir um próximo post (no futuro), no qual explico o que fazer com as notas.\n\n\n\n\n\n\nNota\n\n\n\nOs códigos apresentados foram produzidos sem critérios de qualidade. Melhorias ainda podem ser feitas."
  },
  {
    "objectID": "projetos.html",
    "href": "projetos.html",
    "title": "Projetos",
    "section": "",
    "text": "Aqui você encontra alguns dos meus projetos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR para ciência do solo\n\n\n\n\n\nDisciplina de introdução à linguagem de programação R para estudos em Ciência do Solo - UFRGS\n\n\n\n\n\nGustavo Frosi\n\n\n\n\n\n\nNenhum item correspondente\n\n De volta ao topo"
  },
  {
    "objectID": "projetos/2024-02-05 webscraping python/index.html",
    "href": "projetos/2024-02-05 webscraping python/index.html",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "",
    "text": "Você já se perguntou quanto gastou no mercado? E quais os itens que mais comprou? Bom, se você disse que não, acho melhor começar a pensar, e se você disse que sim, mas não sabe como fazer para buscar esses dados, eu tenho uma boa notícia!\nNeste texto, descrevo como utilizei o Python na criação de um código que automatizou o download das minhas notas fiscais pessoais (NFC: Nota Fiscal de Consumidor). Deixo claro que o código é destinado ao uso pessoal e doméstico. Minha intenção é apenas o controle de gastos financeiros (e outras brincadeiras com dados).\nO exemplo que utilizo aqui é para o site Nota Fiscal Gaúcha e serve apenas para quem utiliza o “benefício”. Fica obvio que é necessário colocar o CPF em todas as compras né.\nAntes de começar a codificar, é necessário baixar o webdriver, uma ferramenta para testes de automação que oferece uma série de recursos para utilizar o navegador. O webdriver a ser baixado depende do navegador que você utiliza e da versão instalada. No meu caso, vou ensinar com o navegador da Google, o Google Chrome na versão 121.0.6167.140.\nPara fazer o download do webdriver, basta acessar o link\nDepois de baixado, é necessário colar o webdriver na pasta onde está o executável do Python. No meu caso, como utilizo o Anaconda, colei no diretório do Anaconda, o mesmo onde fica o Python.\nAgora sim! Com isso, já é possível começar a escrever códigos."
  },
  {
    "objectID": "projetos/2024-02-05 webscraping python/index.html#ajuste-da-chave-de-acesso",
    "href": "projetos/2024-02-05 webscraping python/index.html#ajuste-da-chave-de-acesso",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "Ajuste da chave de acesso",
    "text": "Ajuste da chave de acesso\nDa planilha baixada do site, apenas a coluna que contém a chave de acesso da nota fiscal é relevante. Realizei uma pequena manipulação na planilha, removendo os espaços da coluna da chave de acesso, e a salvei como arquivo CSV.\n\n\n\n\n\n\nNota\n\n\n\nCódigos em R\n\n\n\nlibrary(tidyverse)\n\ndados &lt;- readxl::read_excel(\"Nota Fiscal Gaúcha.xlsx\") |&gt;\n  janitor::clean_names() |&gt;\n  mutate(chave = chave_de_acesso |&gt; str_remove_all(pattern = \"\\\\s\")) |&gt;\n  select(chave)\n\nwrite.csv(x = dados, file = \"notas/para_auto.csv\")"
  },
  {
    "objectID": "projetos/2024-02-05 webscraping python/index.html#encontrando-os-pontos-de-clique",
    "href": "projetos/2024-02-05 webscraping python/index.html#encontrando-os-pontos-de-clique",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "Encontrando os pontos de clique",
    "text": "Encontrando os pontos de clique\n\n\n\n\n\n\nNota\n\n\n\nAgora serão apenas códigos em python\n\n\nO procedimento que apresento aqui é baseado em um algoritmo que controla o mouse do computador, realizando cliques e movimentos programados. Como é de se esperar, é necessário fornecer as coordenadas para guiar os movimentos. Essa é uma tarefa manual, porém, é realizada apenas uma vez e se aplica a todas as notas (baixei mais de 200 notas).\nUtilizei o MouseInfo para identificar os pontos. Após abrir o console do python (melhor fazer pelo console) é só dar os seguintes comandos:\n\nfrom mouseinfo import mouseInfo\n\nmouseInfo()\n\nO vídeo abaixo demonstra o funcionamento do MouseInfo, exibindo as marcações das coordenadas x e y à medida que o mouse é movido.\nVideo\nPara encontar os ponto certo basta realizar um teste com o MouseInfo aberto. Abra o site onde as notas serão baixadas e identifique os pontos onde será necessário realizar os cliques. O atalho F6 pode ser utilizado no MouseInfo para marcar as pontos x e y. Siga os passo:\n1º Passo: Clique em avançar e depois em imprimir Figura 2\n\n\n\n\n\n\nFigura 2\n\n\n\n2º Passo: Clique em imprimir na parte do pdf Figura 3\n\n\n\n\n\n\nFigura 3\n\n\n\n3º Passo: Clique em salvar Figura 4\n\n\n\n\n\n\nFigura 4\n\n\n\nPor padrão, o Windows salva na pasta de downloads, mas é possível alterar para a pasta desejada. Basta encontrar o ponto de clique e realizar a mudança de destino."
  },
  {
    "objectID": "projetos/2024-02-05 webscraping python/index.html#resultado",
    "href": "projetos/2024-02-05 webscraping python/index.html#resultado",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "Resultado",
    "text": "Resultado\nO vídeo exibe o “robô” em ação, realizando a impressão e salvando automaticamente cada uma das notas. Na minha análise, as 205 notas que obtive foram processadas em quase 21 minutos, o que equivale a ~6 segundos por nota (Um computador melhor fará em menos tempo). E você, ocupado com diversas tarefas, conseguiria realizar isso de maneira mais rápida? Mesmo ao atingir a nota de número 100 e perceber que ainda falta mais da metade. Se acha que não, a resposta para isso é simples: programação!\nVideo\nE agora, o que fazer com essas notas? Começar a extrair os dados manualmente? Pagar alguém para fazer? Excluir do computador e dar um ponto final?\nA resposta óbvia é sim, dar um ponto final e excluir. No entanto, se ainda assim você deseja extrair informações dos seus dados, eu aconselho a conferir um próximo post (no futuro), no qual explico o que fazer com as notas.\n\n\n\n\n\n\nNota\n\n\n\nOs códigos apresentados foram produzidos sem critérios de qualidade. Melhorias ainda podem ser feitas."
  },
  {
    "objectID": "projetos/2023-11-01 disciplina de R para ufrgs solos/index.html",
    "href": "projetos/2023-11-01 disciplina de R para ufrgs solos/index.html",
    "title": "R para ciência do solo",
    "section": "",
    "text": "No ano de 2023, foi dado um importante passo na Pós-Graduação em Ciência do Solo da UFRGS: a criação da primeira disciplina totalmente voltada ao ensino e aprendizado da linguagem de programação R. O mais entusiasmante foi poder contribuir com todo esse processo.\nPor iniciativa do professor Tales Tiecher, eu, junto com Gustavo Pesini, construímos uma série de aulas e exercícios práticos, com foco na manipulação de dados, análise e visualização desses dados, voltados para o estudo em Ciência do Solo. O principal objetivo da disciplina foi capacitar os alunos a desenvolverem suas próprias análises de dados utilizando os recursos da linguagem de programação R.\nLembro-me perfeitamente do dia em que o professor Tales fez a provocação sobre a criação de uma disciplina sobre o R. Eu, mais do que ansioso para compartilhar um pouco do que vinha aprendendo ao longo de alguns anos, aceitei na hora. Afinal de contas, trata-se de uma ferramenta muito versátil e extremamente útil na área acadêmica. Aos poucos, fomos dando forma a essa pequena ideia. Busquei a ajuda de alguém que, além de saber muito sobre R, é uma pessoa de confiança e dedicação: Gustavo Pesini. Em pouco tempo, já estávamos com o cronograma e as aulas estruturadas. No dia 19/10/2023, iniciamos a jornada de ensinar (e aprender) a linguagem de programação R com nossos colegas de pós-graduação (Figura 1).\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigura 1: Primeira aula da disciplina de R para Ciência do Solo da UFRGS\n\n\n\n\n\n\n\nUm total de nove aulas foram produzidas (Tabela 1) e ministradas ao longo de pouco mais de um mês. O conteúdo programático começou pelos fundamentos, considerando que alguns alunos nunca haviam tido contato prévio com a ferramenta. Assim, iniciamos com uma introdução ao ambiente, abordando os conceitos mais básicos do funcionamento de uma linguagem de programação. Na segunda etapa, o foco foi direcionado para a análise de dados, incluindo procedimentos de manipulação e visualização de dados, além da aplicação dos principais testes estatísticos. Por fim, a última etapa consistiu em uma breve explanação sobre análise multivariada e na criação de relatórios com o R.\n\n\n\n\nTabela 1: Cronograma das aulas do curso\n\n\n\n\n\n\n\n\nAula\nTópicos\n\n\n\n\n1\nApresentação da disciplina, lógica de programação para não programadores, histórico do R, aplicação à Ciência do Solo, instalação de softwares\n\n\n2\nInterface do R, sintaxe básica, operadores, objetos e classes de objetos no R\n\n\n3\nOperações matemáticas, estruturas de repetição e seleção, funções, organização de planilhas\n\n\n4\nImportação de dados, organização, filtro, seleção, transformação de variáveis, exportação de dados\n\n\n5\nGráficos no R com ggplot2, gramática de gráficos, gráficos de pontos, barras, linhas e composição\n\n\n6\nEstatística descritiva, ANOVA, testes de comparação de médias\n\n\n7\nModelos mistos, correlação e regressões\n\n\n8\nTestes não paramétricos\n\n\n9\nPCA, análise discriminante, relatórios automáticos\n\n\n\n\n\n\n\n\n\n\n\n\nPara mim, foi uma oportunidade incrível participar desta disciplina. Não apenas pela dinâmica de estruturar, organizar e conduzir as atividades, mas também por ensinar algo que terá um impacto direto no trabalho dos meus colegas e amigos da pós-graduação. É claro que, assim como outras, esta disciplina representa apenas um ponto de partida; muito estudo ainda será necessário no futuro.\nFoi fascinante observar como, ao longo do tempo, os alunos foram capazes de realizar todas as tarefas propostas e de avançar de forma autônoma, mesmo após o término da disciplina. Isso é ainda mais relevante considerando que uma ferramenta como a programação não é algo convencional para a maioria das pessoas, mesmo dentro da academia.\nQuero deixar registrado meu agradecimento ao PPGCS por aceitar a iniciativa, ao professor Tales Tiecher pela provocação, incentivo e apoio ao longo desse processo, e ao Gustavo Pesini por colaborar comigo e compartilhar a responsabilidade para que tudo ocorresse conforme o planejado.\n\n\n\n\nPara trazer um pouco das “vozes” e da vivência de quem participou do processo, fiz questão de perguntar a alguns dos envolvidos como foi a experiência e se houve benefícios pessoais.\nAbaixo estão os relatos não apenas das pessoas que viabilizaram e permitiram a realização da disciplina, mas também de quem se dispôs a aprender um pouco sobre a ferramenta.\n\nA disciplina “R Aplicado à Ciência do Solo”, organizada e ministrada com a participação do Doutorando Gustavo Frosi do PPGCS, foi um marco importante na formação e capacitação dos alunos. Ao longo do curso, foram atendidas as expectativas quanto à construção e condução do conteúdo, que proporcionou uma sólida base no uso do software R como ferramenta essencial para análise e visualização de dados na Ciência do Solo. A disciplina destacou a relevância do aprendizado de ferramentas computacionais, independentemente da área, mostrando como elas podem otimizar o trabalho de análise de dados e contribuir para o avanço na interpretação e apresentação de dados. A contribuição dessa disciplina ao PPGCS foi imensa, pois além de enriquecer o currículo, ofereceu aos alunos uma valiosa oportunidade de aprimoramento, capacitando-os para desafios futuros na área científica e profissional. A experiência proporcionada foi um grande diferencial na formação dos alunos do PPGCS da UFGRS. - Tales Tiecher (Professor de Química do Solo do Departamento de Solos da Faculdade de Agronomia da UFRGS)\n\n\nSão perguntas difíceis. Por que eu topei fazer disciplina aquela vez? Eu acho que foi mais por um desafio. Porque quando você tem que passar informação para alguém, você precisa primeiro saber sobre o que tu estás falando. Não necessariamente você precisa dominar aquele assunto, mas entender do que tu estás querendo dizer. Então, acho que foi mais por isso mesmo, sabe? Mais por um desafio. Porque se eu tenho que falar para as pessoas sobre regressão, eu vou atrás de aprender sobre o que é regressão e isso foi importante porque depois deu para ver como resultado que eu tive de ir atrás e buscar material, de buscar um monte de coisa que foi bem bacana. Então, acho que mais por isso. Eu acho que a importância para o programa é bastante grande, visto que a gente usa muito esse tipo de abordagem para avaliar dados. Nós trabalhamos muito com a experimentação agrícola, que envolve esse tipo de análise, que com essas ferramentas se dá para fazer esse tipo de análise de forma rápida, facilitada, automatizada, e que é importante para nós aqui como estudantes na pós-graduação. Acho que seria isso. E, para mim, obviamente, foi algo bastante importante, porque, claro, quando você desafia a fazer um trabalho, tu tens que saber sobre o que tu tá falando, voltando lá no início do que eu estive falando. Mas, com certeza, eu aprendi bastante coisa com as tuas aulas, como aluno também, já que eu estava matriculado e passando algumas coisas também. Então foi mais ou menos isso. - Gustavo Pesini (Mestrando em Ciência do Solo - UFRGS)\n\n\nFazer o curso de R desenvolvido no Programa de Pós-Graduação em Ciência do Solo foi uma experiência transformadora para mim. Eu comecei do zero, sem nenhum conhecimento na área, e com o curso consegui aprender a organizar e analisar dados, além de criar gráficos de forma prática. O que mais gostei foi como os conceitos foram explicados de maneira clara e acessível, o que me ajudou a entender temas que antes pareciam complexos. Esse aprendizado também complementou muito bem os conteúdos da disciplina de estatística que estou estudando. Recomendo o curso do R, principalmente às pessoas que, estão iniciando na análise de dados e querem construir uma base sólida. - Alder Duarte (Doutorando em Ciência do Solo - UFRGS)\n\n\nMinha experiência no curso de R foi muito desafiadora, pois nunca havia trabalhado com programação, e ainda mais considerando análises estatísticas. Assim, foi muito gratificante aprender e descobrir que, com a programação, eu poderia obter uma análise completa sobre meu mundo de dados – e falo “um mundo” porque há muita coisa. A abordagem por parte da equipe que ofereceu o curso facilitou muito meu trabalho, permitindo otimizar meu tempo. - Anahi Ferreira (Mestranda em Ciência do Solo - UFRGS)\n\n\nTive muita satisfação com a disciplina de R. O conteúdo foi relevante e bem estruturado, desde conceitos básicos até aplicações práticas. Isso me permitiu aprender a criar scripts tanto análise dos dados quanto na criação de gráficos para minha pesquisa. Além disso, a introdução de tópicos sobre a visualização dos dados, com o uso do pacote ggplot2, foi uma ótima forma para ver as possibilidades de aplicação do R. Os professores demonstraram grande domínio do R e seus pacotes, sempre disposto a esclarecer dúvidas e oferecer exemplos práticos relacionados a nossa área de pesquisa. No geral, foi uma experiência muito positiva e enriquecedora. Me permitiu ter contato com uma ferramenta muito boa e que será de muita ajuda em meus trabalhos. Hoje, sem necessitar de auxílio do professor, já consigo criar meus próprios scripts para atender as minhas demandas. Agradeço pela oportunidade de participar dessa disciplina. - Kayn Eduardo (Mestrando em Ciência do Solo - UFRGS)\n\n\n\n\nÓbvio que uma parte analítica não poderia faltar!\nRealizei uma pequena análise dos relatos acima. O objetivo foi identificar, no conjunto total de textos, quais emoções foram transmitidas.\nSem muita enrolação, a Figura 2 apresenta as contagens totais de cada emoção. Observa-se que a maioria expressou frases com sentimentos positivos, o que reforça a relevância da disciplina.\n\n\n\n\n\n\n\n\nFigura 2: Emoções passadas pelos relatos da disciplina"
  },
  {
    "objectID": "projetos/2023-11-01 disciplina de R para ufrgs solos/index.html#ajuste-da-chave-de-acesso",
    "href": "projetos/2023-11-01 disciplina de R para ufrgs solos/index.html#ajuste-da-chave-de-acesso",
    "title": "R para ciência do solo",
    "section": "Ajuste da chave de acesso",
    "text": "Ajuste da chave de acesso\nDa planilha baixada do site, apenas a coluna que contém a chave de acesso da nota fiscal é relevante. Realizei uma pequena manipulação na planilha, removendo os espaços da coluna da chave de acesso, e a salvei como arquivo CSV.\n\n\n\n\n\n\nNota\n\n\n\nCódigos em R\n\n\n\nlibrary(tidyverse)\n\ndados &lt;- readxl::read_excel(\"Nota Fiscal Gaúcha.xlsx\") |&gt;\n  janitor::clean_names() |&gt;\n  mutate(chave = chave_de_acesso |&gt; str_remove_all(pattern = \"\\\\s\")) |&gt;\n  select(chave)\n\nwrite.csv(x = dados, file = \"notas/para_auto.csv\")"
  },
  {
    "objectID": "projetos/2023-11-01 disciplina de R para ufrgs solos/index.html#encontrando-os-pontos-de-clique",
    "href": "projetos/2023-11-01 disciplina de R para ufrgs solos/index.html#encontrando-os-pontos-de-clique",
    "title": "R para ciência do solo",
    "section": "Encontrando os pontos de clique",
    "text": "Encontrando os pontos de clique\n\n\n\n\n\n\nNota\n\n\n\nAgora serão apenas códigos em python\n\n\nO procedimento que apresento aqui é baseado em um algoritmo que controla o mouse do computador, realizando cliques e movimentos programados. Como é de se esperar, é necessário fornecer as coordenadas para guiar os movimentos. Essa é uma tarefa manual, porém, é realizada apenas uma vez e se aplica a todas as notas (baixei mais de 200 notas).\nUtilizei o MouseInfo para identificar os pontos. Após abrir o console do python (melhor fazer pelo console) é só dar os seguintes comandos:\n\nfrom mouseinfo import mouseInfo\n\nmouseInfo()\n\nO vídeo abaixo demonstra o funcionamento do MouseInfo, exibindo as marcações das coordenadas x e y à medida que o mouse é movido.\nVideo\nPara encontar os ponto certo basta realizar um teste com o MouseInfo aberto. Abra o site onde as notas serão baixadas e identifique os pontos onde será necessário realizar os cliques. O atalho F6 pode ser utilizado no MouseInfo para marcar as pontos x e y. Siga os passo:\n1º Passo: Clique em avançar e depois em imprimir Figura 2\n\n\n\n\n\n\nFigura 2\n\n\n\n2º Passo: Clique em imprimir na parte do pdf Figura 3\n\n\n\n\n\n\nFigura 3\n\n\n\n3º Passo: Clique em salvar Figura 4\n\n\n\n\n\n\nFigura 4\n\n\n\nPor padrão, o Windows salva na pasta de downloads, mas é possível alterar para a pasta desejada. Basta encontrar o ponto de clique e realizar a mudança de destino."
  },
  {
    "objectID": "projetos/2023-11-01 disciplina de R para ufrgs solos/index.html#resultado",
    "href": "projetos/2023-11-01 disciplina de R para ufrgs solos/index.html#resultado",
    "title": "R para ciência do solo",
    "section": "Resultado",
    "text": "Resultado\nO vídeo exibe o “robô” em ação, realizando a impressão e salvando automaticamente cada uma das notas. Na minha análise, as 205 notas que obtive foram processadas em quase 21 minutos, o que equivale a ~6 segundos por nota (Um computador melhor fará em menos tempo). E você, ocupado com diversas tarefas, conseguiria realizar isso de maneira mais rápida? Mesmo ao atingir a nota de número 100 e perceber que ainda falta mais da metade. Se acha que não, a resposta para isso é simples: programação!\nVideo\nE agora, o que fazer com essas notas? Começar a extrair os dados manualmente? Pagar alguém para fazer? Excluir do computador e dar um ponto final?\nA resposta óbvia é sim, dar um ponto final e excluir. No entanto, se ainda assim você deseja extrair informações dos seus dados, eu aconselho a conferir um próximo post (no futuro), no qual explico o que fazer com as notas.\n\n\n\n\n\n\nNota\n\n\n\nOs códigos apresentados foram produzidos sem critérios de qualidade. Melhorias ainda podem ser feitas."
  },
  {
    "objectID": "projetos/2023-11-01 bananabudget/index.html",
    "href": "projetos/2023-11-01 bananabudget/index.html",
    "title": "BananaBudget",
    "section": "",
    "text": "Você já se perguntou quanto gastou no mercado? E quais os itens que mais comprou? Bom, se você disse que não, acho melhor começar a pensar, e se você disse que sim, mas não sabe como fazer para buscar esses dados, eu tenho uma boa notícia!\nNeste texto, descrevo como utilizei o Python na criação de um código que automatizou o download das minhas notas fiscais pessoais (NFC: Nota Fiscal de Consumidor). Deixo claro que o código é destinado ao uso pessoal e doméstico. Minha intenção é apenas o controle de gastos financeiros (e outras brincadeiras com dados).\nO exemplo que utilizo aqui é para o site Nota Fiscal Gaúcha e serve apenas para quem utiliza o “benefício”. Fica obvio que é necessário colocar o CPF em todas as compras né.\nAntes de começar a codificar, é necessário baixar o webdriver, uma ferramenta para testes de automação que oferece uma série de recursos para utilizar o navegador. O webdriver a ser baixado depende do navegador que você utiliza e da versão instalada. No meu caso, vou ensinar com o navegador da Google, o Google Chrome na versão 121.0.6167.140.\nPara fazer o download do webdriver, basta acessar o link\nDepois de baixado, é necessário colar o webdriver na pasta onde está o executável do Python. No meu caso, como utilizo o Anaconda, colei no diretório do Anaconda, o mesmo onde fica o Python.\nAgora sim! Com isso, já é possível começar a escrever códigos."
  },
  {
    "objectID": "projetos/2023-11-01 bananabudget/index.html#ajuste-da-chave-de-acesso",
    "href": "projetos/2023-11-01 bananabudget/index.html#ajuste-da-chave-de-acesso",
    "title": "BananaBudget",
    "section": "Ajuste da chave de acesso",
    "text": "Ajuste da chave de acesso\nDa planilha baixada do site, apenas a coluna que contém a chave de acesso da nota fiscal é relevante. Realizei uma pequena manipulação na planilha, removendo os espaços da coluna da chave de acesso, e a salvei como arquivo CSV.\n\n\n\n\n\n\nNota\n\n\n\nCódigos em R\n\n\n\nlibrary(tidyverse)\n\ndados &lt;- readxl::read_excel(\"Nota Fiscal Gaúcha.xlsx\") |&gt;\n  janitor::clean_names() |&gt;\n  mutate(chave = chave_de_acesso |&gt; str_remove_all(pattern = \"\\\\s\")) |&gt;\n  select(chave)\n\nwrite.csv(x = dados, file = \"notas/para_auto.csv\")"
  },
  {
    "objectID": "projetos/2023-11-01 bananabudget/index.html#encontrando-os-pontos-de-clique",
    "href": "projetos/2023-11-01 bananabudget/index.html#encontrando-os-pontos-de-clique",
    "title": "BananaBudget",
    "section": "Encontrando os pontos de clique",
    "text": "Encontrando os pontos de clique\n\n\n\n\n\n\nNota\n\n\n\nAgora serão apenas códigos em python\n\n\nO procedimento que apresento aqui é baseado em um algoritmo que controla o mouse do computador, realizando cliques e movimentos programados. Como é de se esperar, é necessário fornecer as coordenadas para guiar os movimentos. Essa é uma tarefa manual, porém, é realizada apenas uma vez e se aplica a todas as notas (baixei mais de 200 notas).\nUtilizei o MouseInfo para identificar os pontos. Após abrir o console do python (melhor fazer pelo console) é só dar os seguintes comandos:\n\nfrom mouseinfo import mouseInfo\n\nmouseInfo()\n\nO vídeo abaixo demonstra o funcionamento do MouseInfo, exibindo as marcações das coordenadas x e y à medida que o mouse é movido.\nVideo\nPara encontar os ponto certo basta realizar um teste com o MouseInfo aberto. Abra o site onde as notas serão baixadas e identifique os pontos onde será necessário realizar os cliques. O atalho F6 pode ser utilizado no MouseInfo para marcar as pontos x e y. Siga os passo:\n1º Passo: Clique em avançar e depois em imprimir Figura 2\n\n\n\n\n\n\nFigura 2\n\n\n\n2º Passo: Clique em imprimir na parte do pdf Figura 3\n\n\n\n\n\n\nFigura 3\n\n\n\n3º Passo: Clique em salvar Figura 4\n\n\n\n\n\n\nFigura 4\n\n\n\nPor padrão, o Windows salva na pasta de downloads, mas é possível alterar para a pasta desejada. Basta encontrar o ponto de clique e realizar a mudança de destino."
  },
  {
    "objectID": "projetos/2023-11-01 bananabudget/index.html#resultado",
    "href": "projetos/2023-11-01 bananabudget/index.html#resultado",
    "title": "BananaBudget",
    "section": "Resultado",
    "text": "Resultado\nO vídeo exibe o “robô” em ação, realizando a impressão e salvando automaticamente cada uma das notas. Na minha análise, as 205 notas que obtive foram processadas em quase 21 minutos, o que equivale a ~6 segundos por nota (Um computador melhor fará em menos tempo). E você, ocupado com diversas tarefas, conseguiria realizar isso de maneira mais rápida? Mesmo ao atingir a nota de número 100 e perceber que ainda falta mais da metade. Se acha que não, a resposta para isso é simples: programação!\nVideo\nE agora, o que fazer com essas notas? Começar a extrair os dados manualmente? Pagar alguém para fazer? Excluir do computador e dar um ponto final?\nA resposta óbvia é sim, dar um ponto final e excluir. No entanto, se ainda assim você deseja extrair informações dos seus dados, eu aconselho a conferir um próximo post (no futuro), no qual explico o que fazer com as notas.\n\n\n\n\n\n\nNota\n\n\n\nOs códigos apresentados foram produzidos sem critérios de qualidade. Melhorias ainda podem ser feitas."
  },
  {
    "objectID": "recap/2024-02-15 BananBudget1/index.html",
    "href": "recap/2024-02-15 BananBudget1/index.html",
    "title": "BananaBudget",
    "section": "",
    "text": "Introdução\n\n\nVocê já pensou qual seu gasto no mercado? Quais os produtos que mais compra? Qual a frequência que vai ao mercado?\nEu e o Diogo já!\n\n\n\n\n\n\n\n\nNeste texto, vamos mostrar como manipulamos notas fiscais de mercado para responder às questões iniciais por meio da programação. Morando em Porto Alegre com mais duas pessoas (totalizando quatro), é fundamental ter um controle de gastos. Após vários meses registrando todos os gastos no mercado, surgiu a seguinte pergunta: “Será que podemos identificar quais produtos compramos com maior ou menor frequência?” (coisa de doido, né?). De certa forma, já sabíamos que, ao utilizar o CPF nas compras, as notas ficam armazenadas em algum lugar, mas não tínhamos certeza de onde.\nNo Rio Grande do Sul, assim como em outros estados, existe um sistema de “recompensa” chamado Nota Fiscal Gaúcha. Ao adicionar o CPF nas notas, você concorre a prêmios e outras vantagens. Além disso, é possível acessar todas as notas fiscais, com informações como data, produtos adquiridos, preços e estabelecimentos.\nUma maneira de obter essas notas é por meio de “web scraping”. Para saber mais sobre esse processo, você pode conferir o Post, onde descrevemos como realizá-lo.\nCom notas na mão (ou no pc) é hora de organizar os dados!\n\n\nExtração de dados dos pdfs\nCriamos uma função chamada “pega_produto()”, essa função identifica padrões no texto e separa as informações em um data frame, onde cada linha representa um produto comprado. Ao aplicar essa função em todas as notas, obtemos uma base de dados com os seguintes campos: Data, Hora, Nome do Produto, Preço do Produto… (Figura 1)\n\n# Carregando os pacotes\nlibrary(pdftools) # manipulação de pdf\nlibrary(tidyverse) # conjunto de pacotes para manipulação e visualização\n\n# Primeiro defini o diretório da pasta com as notas.\npasta &lt;- \"notas/notas/\"\n\n# lista os arquivos dentro da pasta\ndocs &lt;- list.files(pasta, full.names = T)\n\n# a função 'pega_produto' será responsável por encontrar cada linha da nota com os produtos\npega_produto &lt;- function(pdf) {\n  df &lt;-\n    pdf_text(pdf) |&gt;\n    strsplit(\"\\n\") |&gt;\n    unlist() |&gt;\n    enframe(name = NULL, value = \"linha\")\n\n  data &lt;- df |&gt;\n    filter(str_detect(linha, pattern = \"Data de Emissão\")) |&gt;\n    str_extract(pattern = \"\\\\d{2}.\\\\d{2}.\\\\d{4}.\\\\d{2}.\\\\d{2}.\\\\d{2}\")\n\n  produtos &lt;- df |&gt;\n    filter(str_detect(linha, pattern = \"\\\\S\\\\d{4,}\")) |&gt;\n    filter(str_detect(linha, pattern = \"^\\\\s{4,}\\\\d\")) |&gt;\n    mutate(linha = linha |&gt; stringr::str_replace_all(pattern = \"[\\\\s]{3,}\", replacement = \"---\")) |&gt;\n    separate(\n      col = linha, into = c(\n        \"ts\", \"id\", \"nome\", \"quant\",\n        \"unidade\", \"valor_uni\", \"valor_total\"\n      ),\n      sep = \"---\", convert = F\n    ) |&gt;\n    select(-1)\n\n  dados_fim &lt;- mutate(\n    .data = produtos,\n    data = rep(\n      data,\n      length(produtos$id)\n    )\n  ) |&gt;\n    separate(col = data, into = c(\"data\", \"hora\"), sep = \" \") |&gt;\n    mutate(\n      hora = hora |&gt; str_extract(pattern = \"\\\\d{2}\\\\:\\\\d{2}\\\\:\\\\d{2}\"),\n      valor_uni = valor_uni |&gt; stringr::str_replace_all(\n        pattern = \"[\\\\,]\",\n        replacement = \".\"\n      ),\n      valor_total = valor_total |&gt; stringr::str_replace_all(\n        pattern = \"[\\\\,]\",\n        replacement = \".\"\n      )\n    ) |&gt;\n    relocate(data, hora) |&gt;\n    mutate(\n      data = dmy(data),\n      id = as.factor(id),\n      valor_uni = as.numeric(valor_uni),\n      valor_total = as.numeric(valor_total)\n    )\n\n  return(dados_fim)\n}\n\n# criando a base de dados\nbase &lt;- data.frame(data = NULL)\n\n# para utilizar a função pega_produto() em cada nota usamos um loop for e juntamos as linhas com a função bind_rows()\nfor (i in 1:length(docs)) {\n  b1 &lt;- pega_produto(docs[i])\n  base &lt;- base |&gt; bind_rows(b1)\n}\n\n# aqui visualizamos a base\nbase |&gt; glimpse()\n\n# e por fim salvamos\nsave(base, file = \"notas/base.RData\")\n\n\n\n\n\n\n\nFigura 1: base de dados\n\n\n\n\n\nOrganização dos dados\nNossa base de dados foi construída com 205 notas fiscais do período de janeiro a dezembro de 2023. Após uma visualização prévia, decidimos criar uma variável relacionada ao tipo de produto, resultando na variável “categoria” (conforme apresentado na Tabela 1). O número de categorias foi determinado subjetivamente, com a intenção de discriminar adequadamente os produtos.\n\n\n\n\n\nCategoria\nItem\n\n\n\n\nCarboidratos\nPão, Massas, Arroz…\n\n\nDoces\nChocolate, Sorvete, Bolacha…\n\n\nBebidas\nLeite, Refrigerante, Água…\n\n\nEmbutidos\nQueijo, Linguiça Calabresa, Bacon…\n\n\nCarnes E Ovos\nOvo, Carnes Vermelhas, Peito de Frango…\n\n\nHigiene\nDesodorante, Sabonete…\n\n\nFrutas\nBanana, Maça, Uva…\n\n\nVerduras\nTomate, Pepino, Alface…\n\n\nLimpeza\nAmaciante, Detergente…\n\n\nTemperos E Molhos\nMassa de Tomate, Salsa, Orégano…\n\n\n\n\n\nTivemos que tomar algumas decisões em relação aos produtos que iríamos incluir na tabela. O primeiro ponto foi determinar que produtos que tivessem apenas uma compra seriam excluídos. Nossa pergunta inicial não visa produtos específicos, mas sim um padrão de consumo geral.\nUma maneira que encontramos para agrupar produtos foi utilizar apenas a primeira palavra do nome do item. No entanto, observamos dois problemas: o primeiro foi a ocorrência de produtos iguais com nomes iniciais diferentes, enquanto o segundo foi a presença de produtos diferentes com nomes iniciais iguais.\nExemplo 1: A palavra \\(\\textbf{CHOC}\\) e \\(\\textbf{CHO}\\) representava o mesmo produto, chocolate.\nExemplo 2: A palavra \\(\\textbf{MINI}\\) era observada no \\(\\textbf{MINI TOMATE}\\) e no \\(\\textbf{MINI PANETONE}\\).\nEsses casos foram tratados de forma manual e caso a caso.\n\n# realizamos uma organização após uma visualização prêvia das categorias \nbase &lt;- base |&gt; \n  mutate(\n    categoria = as.factor(cat),\n    hora = hms(hora),\n    mes = month(data),\n    inicial = ini\n  ) |&gt;\n  select(!c(cat, ini)) |&gt;\n  mutate(\n    mes = case_match(\n      mes,\n      1 ~ \"jan\",\n      2 ~ \"fev\",\n      3 ~ \"mar\",\n      4 ~ \"abr\",\n      5 ~ \"mai\",\n      6 ~ \"jun\",\n      7 ~ \"jul\",\n      8 ~ \"ago\",\n      9 ~ \"set\",\n      10 ~ \"out\",\n      11 ~ \"nov\",\n      12 ~ \"dez\"\n    ),\n    mes = str_to_title(mes),\n    categoria = str_to_title(categoria),\n    mes = factor(mes, ordered = T, levels = c(\n      \"Jan\", \"Fev\", \"Mar\", \"Abr\", \"Mai\",\n      \"Jun\", \"Jul\", \"Ago\", \"Set\", \"Out\", \"Nov\", \"Dez\"\n    ))\n  ) |&gt; \n  mutate( # aqui é onde realizamos a junção mencionadas nos exemplos 1 e 2 \n    inicial = case_when(\n    inicial == \"CHO\" | inicial == \"BOMBOM\" ~ \"CHOC\",\n    inicial == \"SORVETE\" ~ \"SORV\",\n    inicial == \"BISCOITO\" | inicial == \"COOKIE\" | inicial == \"CLUB\" | inicial == \"BARRA\" ~ \"BISC\",\n    inicial == \"DOCE\" | inicial == \"ECLAIR\" | inicial == \"BIBIS\" ~ \"BALA\",\n    inicial == \"CONFEITO\" | inicial == \"MIST\" ~ \"BOLO\",\n    inicial == \"REFR\" | inicial == \"BIPACK\" ~ \"REFRIG\",\n    inicial == \"VH\" ~ \"VHO\",\n    inicial == \"MINI\" ~ \"TOMATE\",\n    .default = as.character(inicial)\n  ))\n\n\n\nGasto total por categoria\nA primeira visualização foi focada em observar o gasto total em cada uma das categorias e o número de compras efetuadas.\n\n# pacotes utilizados em todos os gráficos\nlibrary(tidyverse)\nlibrary(showtext)\nlibrary(ggtext)\n\n\nbase |&gt;\n  group_by(categoria) |&gt;\n  summarise(\n    valor_total = sum(valor_total),\n    numero = n()\n  ) |&gt;\n  ggplot() +\n  aes(x = fct_reorder(categoria, valor_total), y = valor_total) +\n  # geom_col(fill = \"firebrick\") +\n  geom_col(fill = \"firebrick\") +\n  coord_flip() +\n  geom_richtext(\n    mapping = aes(\n      label = \"O nº diz respeito a quantidade &lt;br&gt; de itens comprados\",\n      x = 4, y = 2000\n    ), size = 4,\n    fill = \"gray70\", label.color = NA,\n    family = \"Black Ops One\",\n    label.padding = unit(c(0.30, 0.30, 0.30, 0.30), \"lines\"),\n  ) +\n  labs(\n    x = element_blank(),\n    y = \"Valor total [R$]\",\n    title = \"Gasto total por categoria\",\n    caption = social_caption\n  ) +\n  geom_text(\n    mapping = aes(label = paste(\"nº\", numero)),\n    nudge_y = -125, col = \"gray98\", size = 5, fontface = \"bold\"\n  ) +\n  theme_minimal(23) +\n  theme(\n    text = element_text(family = \"Black Ops One\", size = 20),\n    plot.background = element_rect(fill = \"gray90\"),\n    plot.caption = element_textbox_simple(size = 12)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nGasto mensal das principais categorias\nO segundo gráfico mostra o gasto mês-a-mês para cada categoria. Para isso utilizamos apenas as 5 maiores categorias em total de gasto.\n\ngg_bonito &lt;- base |&gt;\n  group_by(categoria, mes) |&gt;\n  summarise(\n    valor_total = sum(valor_total),\n    numero = n()\n  ) |&gt;\n  filter(!categoria %in% c(\n    \"Temperos E Molhos\",\n    \"Limpeza\", \"Verduras\",\n    \"Frutas\", \"Higiene\"\n  ))\ngg_bonito2 &lt;- gg_bonito |&gt;\n  group_by(mes) |&gt;\n  mutate(\n    total_mensal = sum(valor_total),\n    valor_cat = total_mensal - valor_total\n  )\n\nggplot(gg_bonito) +\n  aes(\n    x = mes,\n    node = categoria,\n    fill = categoria,\n    value = valor_total\n  ) +\n  geom_sankey_bump(\n    space = 0,\n    type = \"alluvial\",\n    color = \"transparent\",\n    smooth = 6\n  ) +\n  scale_fill_viridis_d(option = \"A\", alpha = .8) +\n  theme_sankey_bump(base_size = 16) +\n  scale_x_discrete(expand = c(.01, .001)) +\n  # coord_cartesian(expand = F, clip = \"off\") +\n  labs(\n    title = \"Despesas mensais em diferentes categorias de alimentos\",\n    y = \"Valor Total Mensal [R$]\",\n    x = element_blank(),\n    fill = NULL,\n    caption = social_caption\n  ) +\n  geom_richtext(\n    mapping = aes(\n      label = \"Espessura da linha indica o  &lt;span style = 'color:tomato;'&gt;gasto da categoria&lt;/span&gt;. &lt;br&gt; O somatório de todas as espessuras &lt;br&gt; indica o &lt;span style = 'color:tomato;'&gt;valor total mensal&lt;/span&gt;.\",\n      x = 3.3, y = 840\n    ), size = 4.4,\n    fill = NA, label.color = NA,\n    family = \"Playfair Display\",\n    label.padding = grid::unit(rep(0, 4), \"pt\")\n  ) +\n  theme(\n    text = element_text(family = \"Playfair Display\", size = 20),\n    legend.position = c(.35, .9),\n    legend.background = element_rect(fill = \"transparent\"),\n    legend.direction = \"horizontal\",\n    legend.text = element_text(size = 15),\n    plot.caption = element_textbox_simple(size = 12)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nGasto mensal e total dos principais produtos\nNa última análise, consideramos as categorias que registraram o maior número de compras. Para isso, utilizamos as seguintes categorias: carboidratos, doces, bebidas, frutas e verduras. Dentro de cada uma dessas categorias, identificamos os produtos mais frequentemente adquiridos e os representamos em um único gráfico.\nÉ importante mencionar que, embora o tomate seja botanicamente classificado como uma fruta, optamos por incluí-lo na categoria verdura. Colocamos ele na categoria verdura pois comemos na salada e não como sobremesa!\n\ndft &lt;- base |&gt;\n  filter(categoria %in% c(\"Carboidratos\", \"Doces\", \"Bebidas\", \"Frutas\", \"Verduras\")) |&gt;\n  filter(inicial %in% c(\"PAO\", \"CHOC\", \"REFRIG\", \"BANANA\", \"TOMATE\")) |&gt;\n  group_by(mes, categoria, inicial) |&gt;\n  summarise(\n    valor_total = sum(valor_total),\n    numero = n()\n  ) |&gt;\n  mutate(inicial = case_match(\n    inicial,\n    \"BANANA\" ~ \"Banana\",\n    \"CHOC\" ~ \"Chocolate\",\n    \"PAO\" ~ \"Pão\",\n    \"REFRIG\" ~ \"Refrigerante\",\n    \"TOMATE\" ~ \"Tomate\"\n  ))\n\nvalor_dez &lt;- dft |&gt; filter(mes == \"Dez\")\n\ntot_maximo &lt;- dft |&gt;\n  group_by(inicial) |&gt;\n  summarise(total = round(sum(valor_total))) |&gt;\n  mutate(\n    texto = c(\n      \"Sweet Banana\", \"Cream Cheese Demo\",\n      \"Bready Alternates Demo\", \"Loki Cola\",\n      \"Sweet Banana\"\n    ),\n    cor = c(\n      \"gold3\", \"chocolate4\", \"darkgoldenrod3\",\n      \"firebrick3\", \"tomato2\"\n    )\n  ) |&gt;\n  full_join(valor_dez)\n\ngithub_icon &lt;- \"&#xf09b\"\ngit_gf &lt;- \"FGu5tav0\"\ngit_dv &lt;- \"DiogoVBol\"\n\nsocial_caption &lt;- glue::glue(\n  \"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{github_icon};&lt;/span&gt;\n  &lt;span style='color: #000000'&gt;{git_gf}&lt;/span&gt; &lt;br&gt; &lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{github_icon};&lt;/span&gt;\n  &lt;span style='color: #000000'&gt;{git_dv}&lt;/span&gt;\"\n)\n\n# com facet ---------------------------------------------------------------\n\ndft |&gt;\n  ggplot() +\n  aes(x = mes, y = valor_total, group = 1) +\n  facet_wrap(~inicial, ncol = 1, scales = \"free_y\") +\n  geom_line(linewidth = 2, col = \"gray40\") +\n  geom_point(mapping = aes(fill = inicial), pch = 21, size = 6, col = \"gray90\", stroke = 2) +\n  labs(\n    x = element_blank(),\n    y = \"Valor Total [R$]\",\n    fill = element_blank(),\n    title = \"Valor mensal pago dos produtos \\nmais consumidos por categoria\",\n    caption = social_caption\n  ) +\n  ggfx::with_shadow(\n    geom_text(\n      data = tot_maximo,\n      mapping = aes(\n        label = inicial,\n        family = texto,\n        x = 3, y = +Inf,\n        col = cor,\n        vjust = 1.4\n      ),\n      nudge_x = 1.3,\n      size = 20,\n      lineheight = 1\n    ),\n    colour = \"gray70\",\n    sigma = 20\n  ) +\n  ylim(0, NA) +\n  scale_x_discrete(expand = expansion(mult = c(0, .20))) +\n  coord_cartesian(clip = \"off\") +\n  geom_text(\n    data = tot_maximo,\n    mapping = aes(\n      label = paste(\"R$\", total),\n      col = cor,\n      x = 12, y = valor_total\n    ),\n    family = \"Banana\",\n    nudge_x = 1.3,\n    size = 10,\n    lineheight = 1\n  ) +\n  scale_color_identity() +\n  scale_fill_manual(values = c(\n    \"gold3\", \"chocolate4\", \"darkgoldenrod3\",\n    \"firebrick3\", \"tomato2\"\n  )) +\n  theme_minimal(28) +\n  theme(\n    strip.text = element_blank(),\n    plot.background = element_rect(fill = \"gray90\"),\n    panel.grid.minor.y = element_blank(),\n    axis.title = element_blank(),\n    axis.text = element_text(family = \"Sweet Banana\"),\n    panel.grid.minor = element_line(),\n    legend.position = \"none\",\n    plot.title = element_text(\n      family = \"Brain Melt regular\",\n      size = 35, hjust = 0\n    ),\n    plot.margin = margin(t = 10, r = 10, b = 10, l = 10),\n    plot.caption = element_textbox_simple(size = 16, hjust = -1, halign = -.05)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nConclusão\nNesse texto, demonstramos como é possível obter informações sobre seus gastos pessoais por meio de web scraping, manipulação e visualização de dados utilizando R e Python. As descobertas aqui foram de caráter exploratório, e uma nova análise com cunho estatístico será realizada em um post futuro. Surgem perguntas interessantes, como: Tenho um dia da semana preferido para ir ao mercado? Ou, a frequência de vezes que vou ao mercado pode prever o preço que gasto no mês?\n\n\n\n\n\n\nNota\n\n\n\nOs códigos apresentados foram produzidos sem critérios de qualidade. Melhorias ainda podem ser feitas.\n\n\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "recap/2024-04-09 artigos doutorandos/index.html",
    "href": "recap/2024-04-09 artigos doutorandos/index.html",
    "title": "Quantos artigos eu preciso ter no currículo até o fim do doutorado em Ciência do Solo?",
    "section": "",
    "text": "A resposta é óbvia: Não sei!\nE não tem como saber, pois, vai depender de perguntas que vão para além do individual de cada um. Agora, não significa que não podemos fazer algumas comparações e tentar sair do escuro. Bem, é exatamente isso que eu trago nesse texto. Não são raros os dias que penso que tudo que faço (da Pós-graduação) leva milhões de anos para ficar pronto e, por consequência, me vejo divagando em uma estrada de pensamentos que não tem fim. Para acalmar minhas expectativas, eu resolvi fazer algo. Gastei parte do meu tempo para tentar encontrar parte da resposta. Assim, investiguei, mesmo que superficialmente, a pergunta: Qual o desempenho dos estudantes de doutorado que já passaram pela pós? Com a esperança de encontrar algo para verificar como está o meu andamento individual. O desempenho é difícil de mensurar e, bem, o que o desempenho realmente mede, né? Mas utilizei o que tinha em meu alcance para traçar uma linha de raciocínio. A informação mais fácil de conseguir de alunos já doutores é o número de artigos que publicaram e que estão no currículo Lattes. Com base nesses números levantei algumas hipóteses: 1. Artigos demandam tempo e o número de publicações reflete o tempo investido. 2. A quantidade de artigos pode indicar as parcerias do aluno. 3. Quanto mais artigos, mais a pessoa se dedica a temas relacionados à pós-graduação. Obviamente, há problemas com essas hipóteses e elas abordam apenas uma parte do problema, mas são as que tenho até o momento. Ainda assim, a necessidade de publicar artigos por parte dos alunos torna essa uma opção interessante a ser considerada.\n\n\nPara minha análise, coletei dados de diversas fontes. A análise foi conduzida exclusivamente com alunos de doutorado que frequentaram o curso de Ciência do Solo entre os anos de 2013 e 2022. O período foi determinado de forma arbitrária, com base no tempo disponível para realizar o trabalho. Como sou aluno da UFRGS, utilizei os dados dos egressos do Programa de Pós-Graduação em Ciência do Solo desta universidade. No entanto, para aumentar a amostra, incluí também dados da pós-graduação em Ciência do Solo da UFSM.\nNos sites de cada programa de pós-graduação (Egressos da UFRGS e Egressos do PPGCS da UFSM), compilei o número e os nomes dos alunos formados em cada um dos anos especificados. Inicialmente, fiquei surpreso ao descobrir que o PPGCS da UFSM possui um levantamento sobre a atuação profissional de seus egressos. Essa é exatamente mais uma das ideias que gostaria de implementar com os alunos do PPGCS da UFRGS, já que desconheço tal informação.\nCom os nomes em mãos, iniciei a tarefa mais trabalhosa de todo o processo: encontrar e baixar o currículo Lattes de cada um deles. Ao todo, foram baixados 86 currículos da UFRGS e 98 da UFSM.\n\n\n\n\n\n\nNota\n\n\n\nOs dados podem ser baixados no meu github link\n\n\nOutra informação importante era determinar os anos em que cada pessoa cursou o doutorado em seus respectivos programas de pós-graduação. Para isso, obtive a base de dados de discentes da CAPES, que abrange o período de 2004 a 2022. Utilizei o currículo Lattes como filtro para identificar os alunos que concluíram o doutorado em cada um dos programas e os anos em que estiveram matriculados.\nA maior dificuldade agora é definir quais artigos cada pessoa publicou durante o doutorado. Inicialmente, não há como fazer essa distinção, pois essa informação não está disponível no Lattes e não posso me dar ao luxo de investir mais tempo nessa investigação. Portanto, estabeleci um critério de corte: considerei apenas os artigos com ano de publicação igual ou anterior ao ano de conclusão do doutorado. Reconheço que, na prática, a maioria dos artigos é publicada no ano seguinte à submissão, e que os alunos tendem a publicar os artigos do doutorado mais próximo do final do curso, o que poderia resultar em anos diferentes. No entanto, essa foi a abordagem que encontrei para manter todos os dados em uma mesma “base”. É importante ressaltar que estamos partindo do zero em termos de informação. Com os resultados obtidos, realizei uma análise descritiva dos dados por meio de histogramas. Além disso, elaborei um gráfico da frequência total de artigos publicados e conduzi uma análise dos títulos dos artigos por meio de uma nuvem de palavras, levando em consideração as palavras mais frequentes encontradas nos artigos. Por fim, realizei uma análise da frequência com que termos como nitrogênio, fósforo e potássio aparecem nos títulos, como uma forma indireta de compreender a tendência ou determinar qual é considerado mais importante.\n\n\n\nDos 184 alunos da amostra, um total de 1517 artigos foram encontrados, porém 4 dos alunos não tinham nenhum artigo em seus currículos Lattes. Isso suscita uma discussão inicial sobre a importância do Lattes e a necessidade de mantê-lo atualizado. O Lattes é um exemplo mundial de uma plataforma bem-sucedida que armazena dados de pesquisadores e alunos. Apesar de suas falhas, é inegável seu valor como um repositório de acesso público. De fato, o Lattes é a fonte de dados para várias pesquisas interessantes. O histograma (Figura 1) mostra que a distribuição de artigos publicados com ano igual ou inferior ao ano de conclusão do doutorado é assimétrica negativa ou se aproxima disso. Com um número maior de pessoas publicando números pequenos de artigos frente a números mais altos.\n Figura 1: Histograma da distribuição do número de artigos por aluno.\n\n\n\n\n\n\nAviso\n\n\n\num modelo de massa de probabilidade será ajustado no futuro\n\n\nA Figura 2 apresenta os dados expressos em termos de frequência (absoluta e acumulada). O número médio de artigos foi de 8; no entanto, devido à natureza assimétrica da curva, a média pode não representar adequadamente os dados. Portanto, a mediana, com um valor de 6 artigos, pode ser mais relevante. Isso revela uma descoberta significativa: o número mais frequente corresponde à própria mediana. Além disso, mais de 50% dos alunos no banco de dados publicaram entre 2 e 8 artigos. A avaliação se isso é muito ou pouco depende de vários aspectos. Outro dado interessante é que 90% dos alunos tiveram entre 0 e 18 artigos. No entanto, ao observar o gráfico, é evidente que números elevados são raros. Espero que esta breve análise auxilie meus colegas de mestrado e doutorado em Ciência do Solo a refletirem sobre sua produção acadêmica.\n Figura 2: Frequência relativa e acumuada do número de artigos por aluno de doutorado.\n\n\nCom os títulos, temos a nuvem de palavras. Essa visualização mostra as palavras mais frequentes nos títulos dos mais de mil artigos avaliados. Como esperado, ‘Solo’ e ‘Brasil’ são as palavras mais comuns. Em seguida, encontramos palavras como ‘produtividade’, ‘diferentes’, ‘nitrogênio’, ‘fósforo’ e assim por diante. Acredito que uma mensagem interessante aqui seja tentar evitar palavras óbvias. Embora seja desafiador, aumentar a diversidade nos títulos é uma prática enriquecedora.\n\n\n\n\n\n\n\nBem, como estou realizando meu doutorado com potássio, achei interessante verificar a frequência com que ele é mencionado nos títulos dos artigos. Surpreendentemente, ele é pouco mencionado. A Figura 3 mostra uma visualização do número de vezes que N, P e K aparecem nos títulos, tanto em português quanto em inglês. É interessante notar a disparidade significativa entre os elementos. Não sei se isso está relacionado à importância, à dificuldade de pesquisa ou a algum outro fator que possa explicar essa diferença. Acredito que ainda não tenhamos descoberto tudo o que podemos sobre nenhum desses elementos.\n Figura 2: Número de vezes que N, P e K foram encontrados nos títulos dos artigos.\n\n\n\n\nPara concluir, determinar o número ideal de artigos é uma tarefa complexa, e esta análise está longe de fornecer uma resposta definitiva. No entanto, é inegável que os dados coletados oferecem informações importantes. Espero que essas descobertas incentivem meus colegas a refletirem sobre suas próprias jornadas acadêmicas. Questões como essa são fascinantes de investigar, e caso surjam dúvidas ou alguém queira contribuir, não hesite em enviar uma mensagem."
  },
  {
    "objectID": "recap/2024-04-09 artigos doutorandos/index.html#metodologia",
    "href": "recap/2024-04-09 artigos doutorandos/index.html#metodologia",
    "title": "Quantos artigos eu preciso ter no currículo até o fim do doutorado em Ciência do Solo?",
    "section": "",
    "text": "Para minha análise, coletei dados de diversas fontes. A análise foi conduzida exclusivamente com alunos de doutorado que frequentaram o curso de Ciência do Solo entre os anos de 2013 e 2022. O período foi determinado de forma arbitrária, com base no tempo disponível para realizar o trabalho. Como sou aluno da UFRGS, utilizei os dados dos egressos do Programa de Pós-Graduação em Ciência do Solo desta universidade. No entanto, para aumentar a amostra, incluí também dados da pós-graduação em Ciência do Solo da UFSM.\nNos sites de cada programa de pós-graduação (Egressos da UFRGS e Egressos do PPGCS da UFSM), compilei o número e os nomes dos alunos formados em cada um dos anos especificados. Inicialmente, fiquei surpreso ao descobrir que o PPGCS da UFSM possui um levantamento sobre a atuação profissional de seus egressos. Essa é exatamente mais uma das ideias que gostaria de implementar com os alunos do PPGCS da UFRGS, já que desconheço tal informação.\nCom os nomes em mãos, iniciei a tarefa mais trabalhosa de todo o processo: encontrar e baixar o currículo Lattes de cada um deles. Ao todo, foram baixados 86 currículos da UFRGS e 98 da UFSM.\n\n\n\n\n\n\nNota\n\n\n\nOs dados podem ser baixados no meu github link\n\n\nOutra informação importante era determinar os anos em que cada pessoa cursou o doutorado em seus respectivos programas de pós-graduação. Para isso, obtive a base de dados de discentes da CAPES, que abrange o período de 2004 a 2022. Utilizei o currículo Lattes como filtro para identificar os alunos que concluíram o doutorado em cada um dos programas e os anos em que estiveram matriculados.\nA maior dificuldade agora é definir quais artigos cada pessoa publicou durante o doutorado. Inicialmente, não há como fazer essa distinção, pois essa informação não está disponível no Lattes e não posso me dar ao luxo de investir mais tempo nessa investigação. Portanto, estabeleci um critério de corte: considerei apenas os artigos com ano de publicação igual ou anterior ao ano de conclusão do doutorado. Reconheço que, na prática, a maioria dos artigos é publicada no ano seguinte à submissão, e que os alunos tendem a publicar os artigos do doutorado mais próximo do final do curso, o que poderia resultar em anos diferentes. No entanto, essa foi a abordagem que encontrei para manter todos os dados em uma mesma “base”. É importante ressaltar que estamos partindo do zero em termos de informação. Com os resultados obtidos, realizei uma análise descritiva dos dados por meio de histogramas. Além disso, elaborei um gráfico da frequência total de artigos publicados e conduzi uma análise dos títulos dos artigos por meio de uma nuvem de palavras, levando em consideração as palavras mais frequentes encontradas nos artigos. Por fim, realizei uma análise da frequência com que termos como nitrogênio, fósforo e potássio aparecem nos títulos, como uma forma indireta de compreender a tendência ou determinar qual é considerado mais importante."
  },
  {
    "objectID": "recap/2024-04-09 artigos doutorandos/index.html#resultados",
    "href": "recap/2024-04-09 artigos doutorandos/index.html#resultados",
    "title": "Quantos artigos eu preciso ter no currículo até o fim do doutorado em Ciência do Solo?",
    "section": "",
    "text": "Dos 184 alunos da amostra, um total de 1517 artigos foram encontrados, porém 4 dos alunos não tinham nenhum artigo em seus currículos Lattes. Isso suscita uma discussão inicial sobre a importância do Lattes e a necessidade de mantê-lo atualizado. O Lattes é um exemplo mundial de uma plataforma bem-sucedida que armazena dados de pesquisadores e alunos. Apesar de suas falhas, é inegável seu valor como um repositório de acesso público. De fato, o Lattes é a fonte de dados para várias pesquisas interessantes. O histograma (Figura 1) mostra que a distribuição de artigos publicados com ano igual ou inferior ao ano de conclusão do doutorado é assimétrica negativa ou se aproxima disso. Com um número maior de pessoas publicando números pequenos de artigos frente a números mais altos.\n Figura 1: Histograma da distribuição do número de artigos por aluno.\n\n\n\n\n\n\nAviso\n\n\n\num modelo de massa de probabilidade será ajustado no futuro\n\n\nA Figura 2 apresenta os dados expressos em termos de frequência (absoluta e acumulada). O número médio de artigos foi de 8; no entanto, devido à natureza assimétrica da curva, a média pode não representar adequadamente os dados. Portanto, a mediana, com um valor de 6 artigos, pode ser mais relevante. Isso revela uma descoberta significativa: o número mais frequente corresponde à própria mediana. Além disso, mais de 50% dos alunos no banco de dados publicaram entre 2 e 8 artigos. A avaliação se isso é muito ou pouco depende de vários aspectos. Outro dado interessante é que 90% dos alunos tiveram entre 0 e 18 artigos. No entanto, ao observar o gráfico, é evidente que números elevados são raros. Espero que esta breve análise auxilie meus colegas de mestrado e doutorado em Ciência do Solo a refletirem sobre sua produção acadêmica.\n Figura 2: Frequência relativa e acumuada do número de artigos por aluno de doutorado.\n\n\nCom os títulos, temos a nuvem de palavras. Essa visualização mostra as palavras mais frequentes nos títulos dos mais de mil artigos avaliados. Como esperado, ‘Solo’ e ‘Brasil’ são as palavras mais comuns. Em seguida, encontramos palavras como ‘produtividade’, ‘diferentes’, ‘nitrogênio’, ‘fósforo’ e assim por diante. Acredito que uma mensagem interessante aqui seja tentar evitar palavras óbvias. Embora seja desafiador, aumentar a diversidade nos títulos é uma prática enriquecedora.\n\n\n\n\n\n\n\nBem, como estou realizando meu doutorado com potássio, achei interessante verificar a frequência com que ele é mencionado nos títulos dos artigos. Surpreendentemente, ele é pouco mencionado. A Figura 3 mostra uma visualização do número de vezes que N, P e K aparecem nos títulos, tanto em português quanto em inglês. É interessante notar a disparidade significativa entre os elementos. Não sei se isso está relacionado à importância, à dificuldade de pesquisa ou a algum outro fator que possa explicar essa diferença. Acredito que ainda não tenhamos descoberto tudo o que podemos sobre nenhum desses elementos.\n Figura 2: Número de vezes que N, P e K foram encontrados nos títulos dos artigos."
  },
  {
    "objectID": "recap/2024-04-09 artigos doutorandos/index.html#conclusão",
    "href": "recap/2024-04-09 artigos doutorandos/index.html#conclusão",
    "title": "Quantos artigos eu preciso ter no currículo até o fim do doutorado em Ciência do Solo?",
    "section": "",
    "text": "Para concluir, determinar o número ideal de artigos é uma tarefa complexa, e esta análise está longe de fornecer uma resposta definitiva. No entanto, é inegável que os dados coletados oferecem informações importantes. Espero que essas descobertas incentivem meus colegas a refletirem sobre suas próprias jornadas acadêmicas. Questões como essa são fascinantes de investigar, e caso surjam dúvidas ou alguém queira contribuir, não hesite em enviar uma mensagem."
  },
  {
    "objectID": "formacao.html",
    "href": "formacao.html",
    "title": "Formação",
    "section": "",
    "text": "Educação\n Atualmente, doutorando em ciência do solo pela Universidade Federal do Rio Grande do Sul  (2022 - ).\n Mestre em ciência do solo pela Universidade Federal do Rio Grande do Sul (UFRGS) (2020 - 2022).\n Engenheiro agrônomo pelo Instituto Federal do Paraná  (2015 - 2019).\n Técnico em Agropecuária pelo Instituto Federal Catarinense  (2012 - 2014).\n\n\nInteresses\n\n\n\n\n\nCiência do Solo\nAnálise de dados\n\n\n\n\nMineralogia\nManipulação\n\n\nQuímica\nInferência\n\n\nFertilidade\nVisualização\n\n\n\n\n\n\n\n\n\nHabilidades\n     R\n     Markdown/Quarto\n     Visualização/Manipulação de dados\n     Modelos\n     Python\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "projetos/2023-11-01 disciplina de R para ufrgs solos/index.html#education",
    "href": "projetos/2023-11-01 disciplina de R para ufrgs solos/index.html#education",
    "title": "Finley Malloc",
    "section": "Education",
    "text": "Education\nUniversity of California, San Diego | San Diego, CA PhD in Mathematics | Sept 2011 - June 2015\nMacalester College | St. Paul MA B.A in Economics | Sept 2007 - June 2011"
  },
  {
    "objectID": "projetos/2023-11-01 disciplina de R para ufrgs solos/index.html#experience",
    "href": "projetos/2023-11-01 disciplina de R para ufrgs solos/index.html#experience",
    "title": "Finley Malloc",
    "section": "Experience",
    "text": "Experience\nWengo Analytics | Head Data Scientist | April 2018 - present\nGeoScynce | Chief Analyst | Spet 2012 - April 2018"
  },
  {
    "objectID": "recap/2024-08-01 regressão linear/index.html#como-ela-se-ajusta",
    "href": "recap/2024-08-01 regressão linear/index.html#como-ela-se-ajusta",
    "title": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos",
    "section": "2.1 Como ela se ajusta?",
    "text": "2.1 Como ela se ajusta?\nPara encontrar a curva com o melhor ajuste, é utilizado o método dos mínimos quadrados. Isso significa que o método “encontra” qual das curvas retorna o menor valor para a soma dos quadrados. Essa soma dos quadrados é obtida calculando a diferença entre o valor observado e o valor predito, elevando essa diferença ao quadrado e, somando tudo.\nEm outras palavras, esse método encontra “a curva que fica mais próxima dos dados observados”. É claro que a quantidade de matemática e estatística por trás de todo esse método é brutal. Aqui apresento apenas uma explicação superficial.\nA Figura 2 mostra uma curva (\\(a\\)) com inclinação zero, que representa o intercepto na média dos valores de \\(y\\). Já em \\(b\\), temos o melhor ajuste possível para uma regressão linear. A primeira curva pode ser considerada um palpite inicial para explicar os dados, ou seja, utilizando o valor da média. A segunda é um avanço, onde \\(y\\) passa a assumir valores dependendo de \\(x\\).\n\n\n\n\n\n\n\n\nFigura 2: Ajsute de curva para média de y (a) e ajsute de menor erro (b)\n\n\n\n\n\nA animação abaixo mostra a reta de regressão assumindo diversos valores para \\(\\beta_{0}\\) e \\(\\beta_{1}\\). É importante observar que ela começa com uma reta na média de \\(y\\) e evolui até alcançar retas para além da mais adequada. Os valores da soma dos quadrados indicam que há uma inclinação que minimiza esse valor, enquanto inclinações anteriores ou posteriores fazem com que a soma dos quadrados aumente."
  },
  {
    "objectID": "recap/2024-08-01 regressão linear/index.html#variável-categórica-na-regressão",
    "href": "recap/2024-08-01 regressão linear/index.html#variável-categórica-na-regressão",
    "title": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos",
    "section": "2.2 Variável categórica na regressão",
    "text": "2.2 Variável categórica na regressão\nEssa é a parte que mais me chama atenção.\nPara que uma variável categórica entre na análise de regressão, ela passa por uma pequena transformação, tornando-se uma variável dummy.\nPor definição, uma variável dummy assume apenas os valores \\(0\\) ou \\(1\\), indicando a presença ou ausência de uma categoria. O número de variáveis dummy criadas é sempre igual a \\(n-1\\), onde \\(n\\) é o número de categorias da variável.\nSe tivermos \\(3\\) grupos em nossa variável, então teremos \\(2\\) variáveis dummy, como mostrado na Tabela 1. Nota-se que um dos grupos sempre terá o valor \\(0\\) em ambas as dummies, pois serve como referência, e os demais grupos serão comparados a ele. Na Tabela 1, o grupo “A” é a referência inicial, mas para as demais comparações, é possível alterar o grupo de referência.\n\n\n\n\nTabela 1: Representação das variáveis dummy\n\n\n\n\n\n\nGrupo\nDummy (D1)\nDummy (D2)\n\n\n\n\nA (ref)\n0\n0\n\n\nB\n1\n0\n\n\nC\n0\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDummy em programas estatísticos\n\n\n\n\n\nA criação das variáveis dummy é totalmente automatizada nos programas estatísticos. Logo, você não precisa criá-las manualmente. No entanto, como exercicio, vale a pena rodar uma regressão criando as próprias dummies e ver que o resultado é exatamente o mesmo que o do computador.\n\n\n\nA equação de regressão geral pode ser descrita conforme Equação 1. Também podemos fazer uma equação para cada grupo (Equação 2, Equação 3 e Equação 4).\n\\[y=\\beta_{0}+\\beta_{1}D1+\\beta_{2}D2+\\epsilon_{i} \\tag{1}\\]\nEquação grupo A:\n\\[y=\\beta_{0}+\\epsilon_{i} \\tag{2}\\]\nEquação grupo B:\n\\[y=\\beta_{0}+\\beta_{1}D1+\\epsilon \\tag{3}\\]\nEquação grupo C:\n\\[y=\\beta_{0}+\\beta_{2}D2+\\epsilon \\tag{4}\\]\nAgora, repare como a Equação 2 é descrita apenas pelo intercepto, pois a variável de grupo assume o valor \\(0\\) em todas as dummies (Tabela 1). Já para os demais grupos aparece na equaçao as dummies em que o valor \\(1\\) é atribuído.\nA interpretação de uma regressão com variáveis dummy é, basicamente, a diferença de média entre os grupos (semelhante a um teste de Tukey). Na Figura 3, podemos ver as médias dos grupos A, B e C e os respectivos \\(\\beta\\)s, que indicam a diferença entre elas. Essa diferença pode ser entendida como uma diferença angular, pois, se as médias são diferentes, forma-se um ângulo (\\(\\neq 0\\)) entre as médias.\n\n\n\n\n\n\n\n\nFigura 3: Representação esquemática da regressão com variável dummy"
  },
  {
    "objectID": "recap/2024-08-01 regressão linear/index.html#requisitosindicadores-de-qualidade-para-a-regressão-linear",
    "href": "recap/2024-08-01 regressão linear/index.html#requisitosindicadores-de-qualidade-para-a-regressão-linear",
    "title": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos",
    "section": "2.3 Requisitos/indicadores de qualidade para a regressão linear",
    "text": "2.3 Requisitos/indicadores de qualidade para a regressão linear\nComo um professor disse uma vez:\n\nO grande perigo é a pessoa apenas saber fazer uma regressão.\n\nEssa frase é uma crítica às pessoas que apenas sabem montar um modelo e sair interpretando. Uma interpretação útil surge de uma regressão bem feita, e, para isso, é necessário conhecer a qualidade do modelo gerado. Abaixo estão os principais critérios para avaliar como seu modelo se comporta.\n\n2.3.1 As observações devem ser independentes\nEsse requisito diz que o valor de uma observação não pode ter influência no valor de outra observação.\n\n\n2.3.2 As variáveis preditivas não devem possuir alta correlação\nTambém chamada de multicolinearidade, a alta correlação entre as variáveis independentes é um aspecto importante a ser considerado. Variáveis com alta correlação podem causar diversos problemas, como distorção dos resultados e interpretações espúrias.\n\n\n2.3.3 Homocedasticidade e normalidade dos resíduos\nA homocedasticidade é semelhante à homogeneidade de variâncias testada na ANOVA. No entanto, a homocedasticidade diz respeito à variância dos erros do modelo (\\(\\epsilon\\)), que deve ser constante em toda a escala ou nos níveis da variável \\(x\\).\nJá a normalidade diz respeito aos erros do modelo, que devem ser aproximadamente normais."
  },
  {
    "objectID": "recap/2024-08-01 regressão linear/index.html#especificando-o-modelo",
    "href": "recap/2024-08-01 regressão linear/index.html#especificando-o-modelo",
    "title": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos",
    "section": "3.1 Especificando o modelo",
    "text": "3.1 Especificando o modelo\nNosso modelo teórico e sem interação pode ser representado como:\n\\[y= \\beta_0 + \\beta_1*dose + \\beta_2*cultivar + \\epsilon\\]"
  },
  {
    "objectID": "recap/2024-08-01 regressão linear/index.html#resultado",
    "href": "recap/2024-08-01 regressão linear/index.html#resultado",
    "title": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos",
    "section": "3.2 Resultado",
    "text": "3.2 Resultado\nA Tabela 3 mostra os resultados da regressão. Na tabela, a primeira coluna representa o intercepto ou a variável \\(x\\). A coluna “Beta” apresenta os coeficientes ajustados, seguida pelo intervalo de confiança para o coeficiente e, por fim, o valor de p.\n\n\n\n\nTabela 3: Resultado da regressão linear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\n1\np-value\n\n\n\n\n(Intercept)\n49.9\n48.2, 51.6\n&lt;0.001\n\n\nCultivar\n\n\n\n\n\n\n\n\n    Cultivar1\n—\n—\n\n\n\n\n    Cultivar2\n-4.44\n-6.30, -2.58\n&lt;0.001\n\n\n    Cultivar3\n-11.4\n-13.3, -9.58\n&lt;0.001\n\n\nDose\n0.103\n0.092, 0.113\n&lt;0.001\n\n\nNo. Obs.\n150\n\n\n\n\n\n\nR²\n0.775\n\n\n\n\n\n\n\n1\nCI = Confidence Interval"
  },
  {
    "objectID": "recap/2024-08-01 regressão linear/index.html#interpretação",
    "href": "recap/2024-08-01 regressão linear/index.html#interpretação",
    "title": "Do caos ao conhecimento:  use y = β0 + β1x + ϵ para explicar seus experimentos",
    "section": "Interpretação",
    "text": "Interpretação\nO modelo criado (Tabela 4) tem um \\(R^2\\) de \\(0,77\\), o que é considerao um valor “bom”. Todas as variáveis \\(x\\) foram significativas (\\(p&lt;0,05\\)). A interpretação de cada variável é:\nCultivar: A Cultivar2 tem uma produtividade em média de 4,44 unidade a menos que a Cultivar1. Já a Cultivar3 tem produtividade média de 11,4 unidades a menos que a Cultivar1. Alterando a referência para a Cultivar2, temos que a Cultivar3 tem produtividade média de 7 unidade a menos que a Cultivar2\nDose: Com relação a dose, a cada aumento de uma unidade temos um aumento na produtividade de 0,103 unidades.\n\n\n\n\nTabela 4: Resultado da regressão linear entre Dose e Cultivar para prever produtividade. “Refe Cultivar1” são os resultados utilizando a categória “Cultivar1” como referência, já “Refe Cultivar2” é utilizada a “Cultivar2”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nRefe Cultivar1\n\n\nRefe Cultivar2\n\n\n\nBeta\n95% CI\n1\np-value\nBeta\n95% CI\n1\np-value\n\n\n\n\n(Intercept)\n49.9\n48.2, 51.6\n&lt;0.001\n45.5\n43.8, 47.2\n&lt;0.001\n\n\nCultivar\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Cultivar1\n—\n—\n\n\n4.44\n2.58, 6.30\n&lt;0.001\n\n\n    Cultivar2\n-4.44\n-6.30, -2.58\n&lt;0.001\n—\n—\n\n\n\n\n    Cultivar3\n-11.4\n-13.3, -9.58\n&lt;0.001\n-7.00\n-8.87, -5.14\n&lt;0.001\n\n\nDose\n0.103\n0.092, 0.113\n&lt;0.001\n0.103\n0.092, 0.113\n&lt;0.001\n\n\nNo. Obs.\n150\n\n\n\n\n\n\n\n\n\n\n\n\nR²\n0.775\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nCI = Confidence Interval"
  },
  {
    "objectID": "recap/2024-08-01 regressão linear/index.html#indicadores-de-qualidade",
    "href": "recap/2024-08-01 regressão linear/index.html#indicadores-de-qualidade",
    "title": "Do caos ao conhecimento:  use y = β0 + β1x + ϵ para explicar seus experimentos",
    "section": "Indicadores de qualidade",
    "text": "Indicadores de qualidade\n\nOutliers\nNa regressão linear, uma das maneira de verificar se há dados influentes para o modelo é por meio da distância de cook3. Existem diferentes interpretações frente a valores de corte para considerar um valor influente. Aqui, utilizo o valor de \\(1\\) como ponto de corte. Há discussões sobre o uso de valores limite para diagnosticos, mas de qualquer forma antes de nada, utilizar o limite de \\(1\\) já é grandiosso.\nPodemos observar na Figura 4 que nenhum ponto chega perto do valor de \\(1\\), portanto aparentemente não temos pontos discrepantes que podem atrapalhar o modelo.\n\n\n\n\n\n\n\n\nFigura 4: Distância de cook para o modelo de regressão\n\n\n\n\n\n\n\nNormalidade dos resíduos\nO Figura 5 mostra o qq-plot dos resíduos. O ideal é que os pontos estejam dispostos perfeitamente em cima da reta, no entando isso é práticamente impossível nas análises do dia-a-dia. Portanto, quanto mais próximo da linha melhor e não temos um ponto de corte ou metrica de qualidade para qq-plot buscamos o qq-plot melhor dados os dados que temos.\nVerificamos que há alguns escapes da linha, mas no geral está ok. Com isso podemos concluir que os resíduos são aproximadamente normais. Além disso, tudo indica que não temos problemas com a homocedasticidade.\n\n\n\n\n\n\n\n\nFigura 5: QQ-plot dos resíduos do modelo\n\n\n\n\n\n\n\nMulticolinearidade\nA tolerância entra as variáveis foi de \\(1\\) (Tabela 5) o que significa uma boa tolerância. Em geral, acima de \\(0,80\\) já temos variáveis que se toleram no modelo.\n\n\n\n\nTabela 5: QQ-plot dos resíduos do modelo\n\n\n\n\n\n\nTerm\nVIF\nTolerance\n\n\n\n\nCultivar\n1\n1\n\n\nDose\n1\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\nz\np\nMethod\nAlternative\n\n\n\n\n2.08806\n0.61766\nDurbin-Watson test\ntrue autocorrelation is greater than 0\n\n\n\n\n\ntolerância: aceitável é a partir de 0.8\nsaídas: remover uma das variáveis, juntar as duas em um fator (um pca), ridge regression\n\n\nHomocedasticidade\nNormalidade (semetria) dos resíduos em todos os níveis da VD (Y)\nHomogeneidade da variância dos resíduos do modelo\nqq-plot do resíduo"
  },
  {
    "objectID": "recap/2024-08-01 regressão linear/index.html#footnotes",
    "href": "recap/2024-08-01 regressão linear/index.html#footnotes",
    "title": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\nFrancis Galton↩︎\nwikipedia↩︎\nDennis Cook↩︎"
  },
  {
    "objectID": "recap/2024-08-01 regressão linear/index.html#sec-interpretacao",
    "href": "recap/2024-08-01 regressão linear/index.html#sec-interpretacao",
    "title": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos",
    "section": "3.3 Interpretação",
    "text": "3.3 Interpretação\nO modelo criado (Tabela 4) tem um \\(R^2\\) de \\(0,77\\), o que é considerado um valor “bom”. Todas as variáveis \\(x\\) foram significativas (\\(p&lt;0,05\\)). A interpretação de cada variável é:\nCultivar: A Cultivar2 tem uma produtividade em média de 4,44 unidades a menos que a Cultivar1. Já a Cultivar3 tem produtividade média de 11,4 unidades a menos que a Cultivar1. Alterando a referência para a Cultivar2, observa-se que a Cultivar3 tem produtividade média de 7 unidades a menos que a Cultivar2\nDose: Com relação a dose, a cada aumento de uma unidade temos um aumento na produtividade de 0,103 unidades.\n\n\n\n\nTabela 4: Resultado da regressão linear entre Dose e Cultivar para prever produtividade. “Refe Cultivar1” são os resultados utilizando a categória “Cultivar1” como referência, já “Refe Cultivar2” é utilizada a “Cultivar2”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nRefe Cultivar1\n\n\nRefe Cultivar2\n\n\n\nBeta\n95% CI\n1\np-value\nBeta\n95% CI\n1\np-value\n\n\n\n\n(Intercept)\n49.9\n48.2, 51.6\n&lt;0.001\n45.5\n43.8, 47.2\n&lt;0.001\n\n\nCultivar\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Cultivar1\n—\n—\n\n\n4.44\n2.58, 6.30\n&lt;0.001\n\n\n    Cultivar2\n-4.44\n-6.30, -2.58\n&lt;0.001\n—\n—\n\n\n\n\n    Cultivar3\n-11.4\n-13.3, -9.58\n&lt;0.001\n-7.00\n-8.87, -5.14\n&lt;0.001\n\n\nDose\n0.103\n0.092, 0.113\n&lt;0.001\n0.103\n0.092, 0.113\n&lt;0.001\n\n\nNo. Obs.\n150\n\n\n\n\n\n\n\n\n\n\n\n\nR²\n0.775\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nCI = Confidence Interval"
  },
  {
    "objectID": "recap/2024-08-01 regressão linear/index.html#sec-qualidade",
    "href": "recap/2024-08-01 regressão linear/index.html#sec-qualidade",
    "title": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos",
    "section": "3.4 Indicadores de qualidade",
    "text": "3.4 Indicadores de qualidade\n\n3.4.1 Outliers\nNa regressão linear, uma das maneiras de verificar se há dados influentes para o modelo é por meio da distância de Cook. Existem diferentes interpretações em relação aos valores de corte para considerar um valor influente. Aqui, utilizo o valor de \\(1\\) como ponto de corte. Há discussões sobre o uso de valores limite para diagnósticos, mas, de qualquer forma, utilizar o limite de \\(1\\) já é melhor que não fazer uma avaliação de outliers.\nPodemos observar na Figura 4 que nenhum ponto se aproxima do valor de \\(1\\), portanto, aparentemente, não temos pontos discrepantes que possam prejudicar o modelo.\n\n\n\n\n\n\n\n\nFigura 4: Distância de cook para o modelo de regressão\n\n\n\n\n\n\n\n3.4.2 Normalidade dos resíduos e homocedasticidade\nA Figura 5 mostra o QQ-plot dos resíduos. O ideal é que os pontos estejam dispostos perfeitamente em cima da reta, mas isso é praticamente impossível nas análises do dia a dia. Portanto, quanto mais próximos da linha, melhor. Não temos um ponto de corte ou métrica de qualidade específicos para o QQ-plot. Buscamos o melhor ajuste possível, dados os dados que temos.\nVerificamos que há alguns desvios em relação à linha, mas, no geral, o resultado é satisfatório. Com isso, podemos concluir que os resíduos são aproximadamente normais. Além disso, tudo indica que não temos problemas com a homocedasticidade.\n\n\n\n\n\n\n\n\nFigura 5: QQ-plot dos resíduos do modelo\n\n\n\n\n\n\n\n3.4.3 Multicolinearidade\nA tolerância entre as variáveis foi de \\(1\\) (Tabela 5) o que significa uma boa tolerância. Em geral, acima de \\(0,80\\) já temos variáveis que se toleram no modelo.\n\n\n\n\nTabela 5: Tolerância entre as variáveis do modelo\n\n\n\n\n\n\nTerm\nVIF\nTolerance\n\n\n\n\nCultivar\n1\n1\n\n\nDose\n1\n1\n\n\n\n\n\n\n\n\nO teste de Durbin-Watson é utilizado para verificar a autocorrelação entre os resíduos da regressão. O valor ideal desse teste é \\(2\\), o que indica a ausência de autocorrelação. Se o valor for maior ou menor que \\(2\\), há indícios de autocorrelação positiva ou negativa, respectivamente.\nA análise do Durbin-Watson (Tabela 6) mostra um valor de \\(2,08\\), ou seja, é aproximadamente \\(2\\) e indica que não temos autocorrelação.\n\n\n\n\nTabela 6: QQ-plot dos resíduos do modelo\n\n\n\n\n\n\nz\np\nMethod\nAlternative\n\n\n\n\n2.08806\n0.61766\nDurbin-Watson test\ntrue autocorrelation is greater than 0"
  },
  {
    "objectID": "recap/2024-08-01 regressão linear/index.html#representação-gráfica-do-modelo",
    "href": "recap/2024-08-01 regressão linear/index.html#representação-gráfica-do-modelo",
    "title": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos",
    "section": "3.5 Representação gráfica do modelo",
    "text": "3.5 Representação gráfica do modelo\nNa Seção 3.3 vimos quais foram os efeitos significativos do modelo, já na Seção 3.4 observamos que o modelo está adequado e explica bem os dados. Agora, criamos uma visualização gráfica para apresentar melhor os resultados. Poderia ter sido feito um gráfico com as médias dos grupos de cultivares, mostrando o intervalo de confiança e uma regressão com as doses, mas preferi representar dessa forma."
  },
  {
    "objectID": "recap/2024-08-21 regressão linear/index.html#como-ela-se-ajusta",
    "href": "recap/2024-08-21 regressão linear/index.html#como-ela-se-ajusta",
    "title": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos",
    "section": "2.1 Como ela se ajusta?",
    "text": "2.1 Como ela se ajusta?\nPara encontrar a curva com o melhor ajuste, é utilizado o método dos mínimos quadrados. Isso significa que o método “encontra” qual das curvas retorna o menor valor para a soma dos quadrados. Essa soma dos quadrados é obtida calculando a diferença entre o valor observado e o valor predito, elevando essa diferença ao quadrado e, somando tudo.\nEm outras palavras, esse método encontra “a curva que fica mais próxima dos dados observados”. É claro que a quantidade de matemática e estatística por trás de todo esse método é brutal. Aqui apresento apenas uma explicação superficial.\nA Figura 2 mostra uma curva (\\(a\\)) com inclinação zero, que representa o intercepto na média dos valores de \\(y\\). Já em \\(b\\), temos o melhor ajuste possível para uma regressão linear. A primeira curva pode ser considerada um palpite inicial para explicar os dados, ou seja, utilizando o valor da média. A segunda é um avanço, onde \\(y\\) passa a assumir valores dependendo de \\(x\\).\n\n\n\n\n\n\n\n\nFigura 2: Ajsute de curva para média de y (a) e ajsute de menor erro (b)\n\n\n\n\n\nA animação abaixo mostra a reta de regressão assumindo diversos valores para \\(\\beta_{0}\\) e \\(\\beta_{1}\\). É importante observar que ela começa com uma reta na média de \\(y\\) e evolui até alcançar retas para além da mais adequada. Os valores da soma dos quadrados indicam que há uma inclinação que minimiza esse valor, enquanto inclinações anteriores ou posteriores fazem com que a soma dos quadrados aumente."
  },
  {
    "objectID": "recap/2024-08-21 regressão linear/index.html#variável-categórica-na-regressão",
    "href": "recap/2024-08-21 regressão linear/index.html#variável-categórica-na-regressão",
    "title": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos",
    "section": "2.2 Variável categórica na regressão",
    "text": "2.2 Variável categórica na regressão\nEssa é a parte que mais me chama atenção.\nPara que uma variável categórica entre na análise de regressão, ela passa por uma pequena transformação, tornando-se uma variável dummy.\nPor definição, uma variável dummy assume apenas os valores \\(0\\) ou \\(1\\), indicando a presença ou ausência de uma categoria. O número de variáveis dummy criadas é sempre igual a \\(n-1\\), onde \\(n\\) é o número de categorias da variável.\nSe tivermos \\(3\\) grupos em nossa variável, então teremos \\(2\\) variáveis dummy, como mostrado na Tabela 1. Nota-se que um dos grupos sempre terá o valor \\(0\\) em ambas as dummies, pois serve como referência, e os demais grupos serão comparados a ele. Na Tabela 1, o grupo “A” é a referência inicial, mas para as demais comparações, é possível alterar o grupo de referência.\n\n\n\n\nTabela 1: Representação das variáveis dummy\n\n\n\n\n\n\nGrupo\nDummy (D1)\nDummy (D2)\n\n\n\n\nA (ref)\n0\n0\n\n\nB\n1\n0\n\n\nC\n0\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDummy em programas estatísticos\n\n\n\n\n\nA criação das variáveis dummy é totalmente automatizada nos programas estatísticos. Logo, você não precisa criá-las manualmente. No entanto, como exercicio, vale a pena rodar uma regressão criando as próprias dummies e ver que o resultado é exatamente o mesmo que o do computador.\n\n\n\nA equação de regressão geral pode ser descrita conforme Equação 1. Também podemos fazer uma equação para cada grupo (Equação 2, Equação 3 e Equação 4).\n\\[y=\\beta_{0}+\\beta_{1}D1+\\beta_{2}D2+\\epsilon_{i} \\tag{1}\\]\nEquação grupo A:\n\\[y=\\beta_{0}+\\epsilon_{i} \\tag{2}\\]\nEquação grupo B:\n\\[y=\\beta_{0}+\\beta_{1}D1+\\epsilon \\tag{3}\\]\nEquação grupo C:\n\\[y=\\beta_{0}+\\beta_{2}D2+\\epsilon \\tag{4}\\]\nAgora, repare como a Equação 2 é descrita apenas pelo intercepto, pois a variável de grupo assume o valor \\(0\\) em todas as dummies (Tabela 1). Já para os demais grupos aparece na equaçao as dummies em que o valor \\(1\\) é atribuído.\nA interpretação de uma regressão com variáveis dummy é, basicamente, a diferença de média entre os grupos (semelhante a um teste de Tukey). Na Figura 3, podemos ver as médias dos grupos A, B e C e os respectivos \\(\\beta\\)s, que indicam a diferença entre elas. Essa diferença pode ser entendida como uma diferença angular, pois, se as médias são diferentes, forma-se um ângulo (\\(\\neq 0\\)) entre as médias.\n\n\n\n\n\n\n\n\nFigura 3: Representação esquemática da regressão com variável dummy"
  },
  {
    "objectID": "recap/2024-08-21 regressão linear/index.html#requisitosindicadores-de-qualidade-para-a-regressão-linear",
    "href": "recap/2024-08-21 regressão linear/index.html#requisitosindicadores-de-qualidade-para-a-regressão-linear",
    "title": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos",
    "section": "2.3 Requisitos/indicadores de qualidade para a regressão linear",
    "text": "2.3 Requisitos/indicadores de qualidade para a regressão linear\nComo um professor disse uma vez:\n\nO grande perigo é a pessoa apenas saber fazer uma regressão.\n\nEssa frase é uma crítica às pessoas que apenas sabem montar um modelo e sair interpretando. Uma interpretação útil surge de uma regressão bem feita, e, para isso, é necessário conhecer a qualidade do modelo gerado. Abaixo estão os principais critérios para avaliar como seu modelo se comporta.\n\n2.3.1 As observações devem ser independentes\nEsse requisito diz que o valor de uma observação não pode ter influência no valor de outra observação.\n\n\n2.3.2 As variáveis preditivas não devem possuir alta correlação\nTambém chamada de multicolinearidade, a alta correlação entre as variáveis independentes é um aspecto importante a ser considerado. Variáveis com alta correlação podem causar diversos problemas, como distorção dos resultados e interpretações espúrias.\n\n\n2.3.3 Homocedasticidade e normalidade dos resíduos\nA homocedasticidade é semelhante à homogeneidade de variâncias testada na ANOVA. No entanto, a homocedasticidade diz respeito à variância dos erros do modelo (\\(\\epsilon\\)), que deve ser constante em toda a escala ou nos níveis da variável \\(x\\).\nJá a normalidade diz respeito aos erros do modelo, que devem ser aproximadamente normais."
  },
  {
    "objectID": "recap/2024-08-21 regressão linear/index.html#especificando-o-modelo",
    "href": "recap/2024-08-21 regressão linear/index.html#especificando-o-modelo",
    "title": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos",
    "section": "3.1 Especificando o modelo",
    "text": "3.1 Especificando o modelo\nNosso modelo teórico e sem interação pode ser representado como:\n\\[y= \\beta_0 + \\beta_1*dose + \\beta_2*cultivar + \\epsilon\\]"
  },
  {
    "objectID": "recap/2024-08-21 regressão linear/index.html#resultado",
    "href": "recap/2024-08-21 regressão linear/index.html#resultado",
    "title": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos",
    "section": "3.2 Resultado",
    "text": "3.2 Resultado\nA Tabela 3 mostra os resultados da regressão. Na tabela, a primeira coluna representa o intercepto ou a variável \\(x\\). A coluna “Beta” apresenta os coeficientes ajustados, seguida pelo intervalo de confiança para o coeficiente e, por fim, o valor de p.\n\n\n\n\nTabela 3: Resultado da regressão linear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\n1\np-value\n\n\n\n\n(Intercept)\n49.9\n48.2, 51.6\n&lt;0.001\n\n\nCultivar\n\n\n\n\n\n\n\n\n    Cultivar1\n—\n—\n\n\n\n\n    Cultivar2\n-4.44\n-6.30, -2.58\n&lt;0.001\n\n\n    Cultivar3\n-11.4\n-13.3, -9.58\n&lt;0.001\n\n\nDose\n0.103\n0.092, 0.113\n&lt;0.001\n\n\nNo. Obs.\n150\n\n\n\n\n\n\nR²\n0.775\n\n\n\n\n\n\n\n1\nCI = Confidence Interval"
  },
  {
    "objectID": "recap/2024-08-21 regressão linear/index.html#sec-interpretacao",
    "href": "recap/2024-08-21 regressão linear/index.html#sec-interpretacao",
    "title": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos",
    "section": "3.3 Interpretação",
    "text": "3.3 Interpretação\nO modelo criado (Tabela 4) tem um \\(R^2\\) de \\(0,77\\), o que é considerado um valor “bom”. Todas as variáveis \\(x\\) foram significativas (\\(p&lt;0,05\\)). A interpretação de cada variável é:\nCultivar: A Cultivar2 tem uma produtividade em média de 4,44 unidades a menos que a Cultivar1. Já a Cultivar3 tem produtividade média de 11,4 unidades a menos que a Cultivar1. Alterando a referência para a Cultivar2, observa-se que a Cultivar3 tem produtividade média de 7 unidades a menos que a Cultivar2\nDose: Com relação a dose, a cada aumento de uma unidade temos um aumento na produtividade de 0,103 unidades.\n\n\n\n\nTabela 4: Resultado da regressão linear entre Dose e Cultivar para prever produtividade. “Refe Cultivar1” são os resultados utilizando a categória “Cultivar1” como referência, já “Refe Cultivar2” é utilizada a “Cultivar2”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nRefe Cultivar1\n\n\nRefe Cultivar2\n\n\n\nBeta\n95% CI\n1\np-value\nBeta\n95% CI\n1\np-value\n\n\n\n\n(Intercept)\n49.9\n48.2, 51.6\n&lt;0.001\n45.5\n43.8, 47.2\n&lt;0.001\n\n\nCultivar\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Cultivar1\n—\n—\n\n\n4.44\n2.58, 6.30\n&lt;0.001\n\n\n    Cultivar2\n-4.44\n-6.30, -2.58\n&lt;0.001\n—\n—\n\n\n\n\n    Cultivar3\n-11.4\n-13.3, -9.58\n&lt;0.001\n-7.00\n-8.87, -5.14\n&lt;0.001\n\n\nDose\n0.103\n0.092, 0.113\n&lt;0.001\n0.103\n0.092, 0.113\n&lt;0.001\n\n\nNo. Obs.\n150\n\n\n\n\n\n\n\n\n\n\n\n\nR²\n0.775\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nCI = Confidence Interval"
  },
  {
    "objectID": "recap/2024-08-21 regressão linear/index.html#sec-qualidade",
    "href": "recap/2024-08-21 regressão linear/index.html#sec-qualidade",
    "title": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos",
    "section": "3.4 Indicadores de qualidade",
    "text": "3.4 Indicadores de qualidade\n\n3.4.1 Outliers\nNa regressão linear, uma das maneiras de verificar se há dados influentes para o modelo é por meio da distância de Cook. Existem diferentes interpretações em relação aos valores de corte para considerar um valor influente. Aqui, utilizo o valor de \\(1\\) como ponto de corte. Há discussões sobre o uso de valores limite para diagnósticos, mas, de qualquer forma, utilizar o limite de \\(1\\) já é melhor que não fazer uma avaliação de outliers.\nPodemos observar na Figura 4 que nenhum ponto se aproxima do valor de \\(1\\), portanto, aparentemente, não temos pontos discrepantes que possam prejudicar o modelo.\n\n\n\n\n\n\n\n\nFigura 4: Distância de cook para o modelo de regressão\n\n\n\n\n\n\n\n3.4.2 Normalidade dos resíduos e homocedasticidade\nA Figura 5 mostra o QQ-plot dos resíduos. O ideal é que os pontos estejam dispostos perfeitamente em cima da reta, mas isso é praticamente impossível nas análises do dia a dia. Portanto, quanto mais próximos da linha, melhor. Não temos um ponto de corte ou métrica de qualidade específicos para o QQ-plot. Buscamos o melhor ajuste possível, dados os dados que temos.\nVerificamos que há alguns desvios em relação à linha, mas, no geral, o resultado é satisfatório. Com isso, podemos concluir que os resíduos são aproximadamente normais. Além disso, tudo indica que não temos problemas com a homocedasticidade.\n\n\n\n\n\n\n\n\nFigura 5: QQ-plot dos resíduos do modelo\n\n\n\n\n\n\n\n3.4.3 Multicolinearidade\nA tolerância entre as variáveis foi de \\(1\\) (Tabela 5) o que significa uma boa tolerância. Em geral, acima de \\(0,80\\) já temos variáveis que se toleram no modelo.\n\n\n\n\nTabela 5: Tolerância entre as variáveis do modelo\n\n\n\n\n\n\nTerm\nVIF\nTolerance\n\n\n\n\nCultivar\n1\n1\n\n\nDose\n1\n1\n\n\n\n\n\n\n\n\nO teste de Durbin-Watson é utilizado para verificar a autocorrelação entre os resíduos da regressão. O valor ideal desse teste é \\(2\\), o que indica a ausência de autocorrelação. Se o valor for maior ou menor que \\(2\\), há indícios de autocorrelação positiva ou negativa, respectivamente.\nA análise do Durbin-Watson (Tabela 6) mostra um valor de \\(2,08\\), ou seja, é aproximadamente \\(2\\) e indica que não temos autocorrelação.\n\n\n\n\nTabela 6: QQ-plot dos resíduos do modelo\n\n\n\n\n\n\nz\np\nMethod\nAlternative\n\n\n\n\n2.08806\n0.61766\nDurbin-Watson test\ntrue autocorrelation is greater than 0"
  },
  {
    "objectID": "recap/2024-08-21 regressão linear/index.html#representação-gráfica-do-modelo",
    "href": "recap/2024-08-21 regressão linear/index.html#representação-gráfica-do-modelo",
    "title": "Do caos ao conhecimento:  use \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\) para explicar seus experimentos",
    "section": "3.5 Representação gráfica do modelo",
    "text": "3.5 Representação gráfica do modelo\nNa Seção 3.3 vimos quais foram os efeitos significativos do modelo, já na Seção 3.4 observamos que o modelo está adequado e explica bem os dados. Agora, criamos uma visualização gráfica para apresentar melhor os resultados. Poderia ter sido feito um gráfico com as médias dos grupos de cultivares, mostrando o intervalo de confiança e uma regressão com as doses, mas preferi representar dessa forma."
  },
  {
    "objectID": "trabalho_pos/trabalhos/trab1.html",
    "href": "trabalho_pos/trabalhos/trab1.html",
    "title": "Trabalho 1",
    "section": "",
    "text": "Teste de trabalhos\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "trabalho_pos/index.html",
    "href": "trabalho_pos/index.html",
    "title": "Resumos e apresentações em eventos",
    "section": "",
    "text": "2024\n\n\n\n\n2023\n\n\n\n\nXXIII CLACS | XXXVIII CBCS\n\n\nEstimativa da área superficial específica por adsorção de água através de parâmetros físicos e químicos\n\n\n\n\n\n\n\n\n2022\n\n\n\n\nXXVIII - Congreso Argentino de la Ciencia del Suelo\n\n\nFertilização do solo com resíduo industrial orgânico salino: Sódio e dispersão das partículas\n\n\n\n\n\n\n\n\n2021\n\n\n\n\n2020\n\n\n\n\n2019\n\n\n\n\nXXXVII - Congresso Brasileiro de Ciência do Solo\n\n\nRespiração microbiana e dinâmica de nutrientes em solo fertilizado com resíduo industrial salino\n\n\n\n\n2018\n\n\n\n\nXII - Reunião Sul Brasileira de Ciência do Solo\n\n\nFósforo e potássio disponível no solo após o cultivo de tomate cereja\n\n\n\n\nVIII - Contextos e Conceitos\n\n\nDispersão da fração argila em solo com calcário incorporado por formas distintas\n\n\n\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "trabalho_pos/resumos/trab1.html",
    "href": "trabalho_pos/resumos/trab1.html",
    "title": "Trabalho 1",
    "section": "",
    "text": "Teste de trabalhos\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "trabalho_pos/resumos/cbcs_2023/trab1.html",
    "href": "trabalho_pos/resumos/cbcs_2023/trab1.html",
    "title": "XXIII CLACS | XXXVIII CBCS",
    "section": "",
    "text": "Resumo\nA área superficial específica (ASE) do solo é uma propriedade relacionada ao comportamento químico e físico do solo, como processos de adsorção e de agregação. O método da adsorção de água (ASEH2O) tem sido utilizado com sucesso em estudos da Ciência do Solo. Porém, essa metodologia é demorada e utiliza reagentes químicos como o pentóxido de fósforo. Por ser uma propriedade que emerge da interação dos componentes do solo, o objetivo deste trabalho foi estimar a ASEH2O a partir de parâmetros físicos e químicos do solo. Em amostras do horizonte A de 76 solos do Rio Grande do Sul, foram determinados, além da ASEH2O, os teores de carbono orgânico total (COT), argila, silte, areia, e de ferro extraídos por oxalato de amônio (Feo) e por ditionito-citrato-bicarbonato de sódio (Fed). Modelos de regressões múltiplas foram testados. A qualidade dos modelos foi avaliada pelos valores de AIC, R2adj, RMSE e MAE. A ASEH2O se correlacionou com todas as variáveis preditoras, na ordem: COT&gt;areia&gt;Feo&gt;argila&gt;Fed&gt;silte. A variável argila foi removida devido a multicolinearidade com a areia. Foram encontrados um total de 13 modelos significativos (p&lt;0,05), porém apenas os 4 melhores são apresentados. O melhor modelo foi com a inclusão de areia, COT, Feo e silte [ASE = (6,2645–0,1626areia + 0,3123COT+1,1365 Feo – 0,0895silte)2; AIC = 202, MAE = 0.64, RMSE = 0.84 e R2adj = 0.79]. Na sequência, estão dois modelos com 3 variáveis. O primeiro teve a inclusão da areia, COT e Feo (AIC = 208, MAE = 0.69, RMSE = 0.89 e R2adj = 0.77), enquanto o segundo com COT, Feo e Fed (AIC = 205, MAE = 0.67, RMSE = 0.87 e R2adj = 0.77). Por fim, o 4º modelo que utilizou apenas areia e COT [ASE = (5,5765 – 0,1552areia + 0,4570COT)2; AIC = 214, MAE = 0.70, RMSE = 0.94 e R2adj = 0.74]. Em suma, parâmetros químicos e físicos podem ser utilizados em modelos para a inferência da ASEH2O, o que permite maior rapidez e menor produção de resíduos.\n\n\nPalavras chave:\nASEH2O; Regressão múltipla; Parâmetros físicos; Parâmetros químicos\n\n\nPôster\n\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "trabalho_pos/resumos/sbcs_2023/trab1.html",
    "href": "trabalho_pos/resumos/sbcs_2023/trab1.html",
    "title": "XXIII CLACS | XXXVIII CBCS",
    "section": "",
    "text": "Resumo\nA área superficial específica (ASE) do solo é uma propriedade relacionada ao comportamento químico e físico do solo, como processos de adsorção e de agregação. O método da adsorção de água (ASEH2O) tem sido utilizado com sucesso em estudos da Ciência do Solo. Porém, essa metodologia é demorada e utiliza reagentes químicos como o pentóxido de fósforo. Por ser uma propriedade que emerge da interação dos componentes do solo, o objetivo deste trabalho foi estimar a ASEH2O a partir de parâmetros físicos e químicos do solo. Em amostras do horizonte A de 76 solos do Rio Grande do Sul, foram determinados, além da ASEH2O, os teores de carbono orgânico total (COT), argila, silte, areia, e de ferro extraídos por oxalato de amônio (Feo) e por ditionito-citrato-bicarbonato de sódio (Fed). Modelos de regressões múltiplas foram testados. A qualidade dos modelos foi avaliada pelos valores de AIC, R2adj, RMSE e MAE. A ASEH2O se correlacionou com todas as variáveis preditoras, na ordem: COT&gt;areia&gt;Feo&gt;argila&gt;Fed&gt;silte. A variável argila foi removida devido a multicolinearidade com a areia. Foram encontrados um total de 13 modelos significativos (p&lt;0,05), porém apenas os 4 melhores são apresentados. O melhor modelo foi com a inclusão de areia, COT, Feo e silte [ASE = (6,2645–0,1626areia + 0,3123COT+1,1365 Feo – 0,0895silte)2; AIC = 202, MAE = 0.64, RMSE = 0.84 e R2adj = 0.79]. Na sequência, estão dois modelos com 3 variáveis. O primeiro teve a inclusão da areia, COT e Feo (AIC = 208, MAE = 0.69, RMSE = 0.89 e R2adj = 0.77), enquanto o segundo com COT, Feo e Fed (AIC = 205, MAE = 0.67, RMSE = 0.87 e R2adj = 0.77). Por fim, o 4º modelo que utilizou apenas areia e COT [ASE = (5,5765 – 0,1552areia + 0,4570COT)2; AIC = 214, MAE = 0.70, RMSE = 0.94 e R2adj = 0.74]. Em suma, parâmetros químicos e físicos podem ser utilizados em modelos para a inferência da ASEH2O, o que permite maior rapidez e menor produção de resíduos.\n\n\nPalavras chave:\nASEH2O; Regressão múltipla; Parâmetros físicos; Parâmetros químicos\n\n\nPôster\n\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "trabalho_pos/resumos/sbcs_2023/gustavo/trab1.html",
    "href": "trabalho_pos/resumos/sbcs_2023/gustavo/trab1.html",
    "title": "XXIII CLACS | XXXVIII CBCS",
    "section": "",
    "text": "Resumo\nA área superficial específica (ASE) do solo é uma propriedade relacionada ao comportamento químico e físico do solo, como processos de adsorção e de agregação. O método da adsorção de água (ASEH2O) tem sido utilizado com sucesso em estudos da Ciência do Solo. Porém, essa metodologia é demorada e utiliza reagentes químicos como o pentóxido de fósforo. Por ser uma propriedade que emerge da interação dos componentes do solo, o objetivo deste trabalho foi estimar a ASEH2O a partir de parâmetros físicos e químicos do solo. Em amostras do horizonte A de 76 solos do Rio Grande do Sul, foram determinados, além da ASEH2O, os teores de carbono orgânico total (COT), argila, silte, areia, e de ferro extraídos por oxalato de amônio (Feo) e por ditionito-citrato-bicarbonato de sódio (Fed). Modelos de regressões múltiplas foram testados. A qualidade dos modelos foi avaliada pelos valores de AIC, R2adj, RMSE e MAE. A ASEH2O se correlacionou com todas as variáveis preditoras, na ordem: COT&gt;areia&gt;Feo&gt;argila&gt;Fed&gt;silte. A variável argila foi removida devido a multicolinearidade com a areia. Foram encontrados um total de 13 modelos significativos (p&lt;0,05), porém apenas os 4 melhores são apresentados. O melhor modelo foi com a inclusão de areia, COT, Feo e silte [ASE = (6,2645–0,1626areia + 0,3123COT+1,1365 Feo – 0,0895silte)2; AIC = 202, MAE = 0.64, RMSE = 0.84 e R2adj = 0.79]. Na sequência, estão dois modelos com 3 variáveis. O primeiro teve a inclusão da areia, COT e Feo (AIC = 208, MAE = 0.69, RMSE = 0.89 e R2adj = 0.77), enquanto o segundo com COT, Feo e Fed (AIC = 205, MAE = 0.67, RMSE = 0.87 e R2adj = 0.77). Por fim, o 4º modelo que utilizou apenas areia e COT [ASE = (5,5765 – 0,1552areia + 0,4570COT)2; AIC = 214, MAE = 0.70, RMSE = 0.94 e R2adj = 0.74]. Em suma, parâmetros químicos e físicos podem ser utilizados em modelos para a inferência da ASEH2O, o que permite maior rapidez e menor produção de resíduos.\n\n\nPalavras chave:\nASEH2O; Regressão múltipla; Parâmetros físicos; Parâmetros químicos\n\n\nPôster\n\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "trabalho_pos/resumos/contexto_2018/gustavo/trab1.html",
    "href": "trabalho_pos/resumos/contexto_2018/gustavo/trab1.html",
    "title": "VIII Contextos e Conceitos",
    "section": "",
    "text": "Resumo\nA agregação é umas das características relacionadas com a estrutura física do solo. A estruturação do solo favorece a formação de um ambiente propício para desenvolvimento das raízes das plantas, armazenamento de água e trocas gasosas. O processo de formação de agregados é complexo e depende de vários fatores. O precursor da agregação do solo é a floculação da argila, favorecida pelo alto teor de matéria orgânica do solo, óxidos de ferro e alumínio e cátions polivalentes (KLEIN, 2014). A calagem é uma prática que contribui nesse processo, adicionando íons divalentes como o cálcio e magnésio, que podem formar ligações químicas entre as partículas organo-minerais (Seta & Karathanasis, 1997). No entanto, operações como a aração e gradagem, utilizadas na incorporação de corretivos, desagregam e aumentam a erodibilidade do solo. O objetivo deste trabalho foi verificar o teor de argila dispersa em água e o grau de floculação da argila em um solo que recebeu calcário e foi submetido a diferentes formas de incorporação do corretivo. O experimento foi realizado no município de mangueirinha, onde predomina clima temperado – Cfb, segundo classificação de Köppen. O solo foi classificado como Latossolo Vermelho (EMBRAPA, 2006). Amostras de solo da camada 0-10, 10-20, 20-30 e 30-40 cm foram coletadas anteriormente à instalação do experimento e submetidas à análise química. A recomendação da dosagem de calcário para ajuste do pH a 6, na camada 0-20 cm, foi de 4,8 Mg ha-1 (CQFS-RS/SC, 2016). O experimento foi composto por seis tratamentos: aplicação do calcário + escarificação até as profundidades 10cm (E1); 20cm (E2); 30cm (E3) e 40 cm (E4); revolvimento com arado (A); aplicação do calcário em superfície sem incorporação (S) e testemunha sem aplicação de calcário (T). Os tratamentos estavam dispostos em blocos ao acaso, com 4 repetições em parcelas de 12m2. Seis meses após a aplicação e incorporação do corretivo, amostras de solo das camadas descritas acima foram coletadas novamente. Todas as amostras de solo (anterior e seis meses após a aplicação do calcário) foram levadas ao laboratório, secadas, moídas e passadas em peneira de malha 2mm, para obtenção da terra fina seca ao ar (TFSA), na qual realizou-se as análises. A determinação de argila total foi realizada pelo método da pipeta após a dispersão da fração com NaOH 1 mol L-1; a argila dispersa em água foi realizada pelo método da pipeta sem dispersante (Embrapa, 2017). Com os teores de argila total e dispersa em água, determinou-se o grau de floculação, conforme (Embrapa, 2017). A análise de variância foi realizada e quando significativa (p&lt;0,05) teste de Tukey foi aplicado com auxílio do software Estatistix 10.0. Os teores de argila total foram de 283 g kg-1, 382 g kg-1, 421 g kg-1, 429 g kg-1, para as camadas 0 a 10 cm, 10 a 20 cm, 20 a 30 cm, 30 a 40 cm, respectivamente. Para os teores de argila natural e grau de floculação, não houve interação (p&gt;0,05) entre os tratamentos e as profundidades. A argila dispersa em água variou de 28 a 64 g kg-1 e foi influenciada somente pelos tratamentos. Esta variação ocasionou a alteração dos valores de floculação da fração argila, os quais variaram de 92 a 83%. Nos tratamentos T e S foram observados os maiores teores de argila dispersa em água e os menores valores de grau de floculação da argila, diferenciando-se dos tratamentos E4 e A. A semelhança entre os valores de T e S ocorreu, pois, o efeito do aumento do teor de Ca e Mg na floculação da argila no tratamento S pode ter ocorrido com mesma intensidade do que o efeito da dispersão da argila pelo aumento do pH do solo, ou seja, os dois efeitos se anularam. Entretanto, quando houve incorporação do calcário em profundidades maiores (E4 e A), diluindo o teor de Ca, Mg e o efeito do pH do solo, fez com que o efeito do aumento do teor de Ca e Mg se sobressaísse ao efeito do aumento do pH. Zanfolin et al. (2015) também observaram efeito positivo para o grau de floculação da argila quando aplicado calcário e incorporado em um Argissolo Vermelho distroférrico. Conclui-se que a aplicação de calcário em superfície sem revolvimento do solo pode aumentar a dispersão da argila e reduzir o grau de floculação da mesma, podendo influenciar negativamente na agregação do solo, infiltração e armazenamento de água.\n\n\nPalavras chave:\nFloculação de argila; agregação; calagem\n\n\nPôster\n\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "trabalho_pos/resumos/contexto_2018/wesley/trab1.html",
    "href": "trabalho_pos/resumos/contexto_2018/wesley/trab1.html",
    "title": "VIII Contextos e Conceitos",
    "section": "",
    "text": "Resumo\nA soja é uma das principais culturas do agronegócio brasileiro. O Brasil é o segundo maior produtor mundial de soja. A área plantada na safra 2016/2017 foi de 33.915,00 milhões de hectares, com produção de 114.095 milhões de toneladas (CONAB, 2017), sendo o Paraná o segundo maior produtor da cultura no país (CONAB, 2018). O plantio da cultura da soja deve seguir o zoneamento agroclimático para evitar perdas na produtividade. O período ideal da semeadura da soja é afetado por questões climáticas que podem interferir de maneira significativa no desenvolvimento da cultura (Morando et al., 2014). Técnicas como a fertilização demandam de constantes reabastecimento da semeadora/adubadora e aumentam o tempo necessário para a etapa da semeadura influenciando na capacidade operacional da atividade agrícola (PAULA, 2018). Todavia, técnicas agrícolas que que possibilitem diminuir o tempo gasto com as operações de plantio da cultura tem sido propostas, porém deve-se evitar que tais artifícios interfiram negativamente na produtividade da cultura. Uma técnica que tem sido utilizada por agricultores para diminuir o tempo gasto na operação de semeadura é a adubação de sistemas, ou seja, utilizar toda a adubação necessária para as culturas de inverno e verão na cultura de inverno. Posteriormente, na cultura de verão utiliza-se somente as sementes. Tal técnica não está totalmente consolidada e resultados contraditórios são gerados. O objetivo do trabalho foi avaliar os componentes de produtividade da soja em diferentes sistemas de adubação. O experimento foi conduzido em um cultivo sucessivo de cevada - Hordeum vulgare (inverno 2017) e soja - Glycine max (verão 2017/2018), em uma propriedade rural no município de Mangueirinha-PR. O clima da região é classificado como Cfb (Classificação de Köppen-Geiser) e o solo é classificado como Latossolo Vermelho distroférrico (EMBRAPA, 2007). Uma amostra de solo composta da área experimental foi coletada e encaminhada à análise laboratorial. Os parâmetros químicos obtidos foram: pHCaCl2 5,0; matéria orgânica 50,93 g dm-3 ; fósforo 6,87 mg dm-3, potássio 0,18 cmolc dm-3, cálcio 6,5 cmolc dm-3, magnésio 2,4 cmolc dm-3, alumínio + hidrogênio 4,2 cmolc dm-3; e saturação por bases (V%) 68,37%. A recomendação de adubação foi realizada de acordo com o Manual de Adubação e Calagem para o Estado do Paraná (2017). Os tratamentos foram: a) testemunha (T) – nenhum cultivo recebeu adubação; b) adubação total na cultura da cevada (C+S) – a cultura da cevada recebeu a adubação recomendada para a cevada mais a recomendada para a cultura da soja (600 kg ha-1 de NPK 08- 30-20), ou seja, a soja foi cultivada sem adubação no momento do plantio; c) dose recomendada (RE) – cada cultura recebeu no momento da semeadura a quantidade de fertilizante (cevada recebeu 200 kg ha-1 de NPK 08-30-20 e a soja recebeu 521,5 kg ha-1 de NPK 02-23-23). As parcelas experimentais (16 m²) estavam dispostas em delineamento experimental inteiramente casualizado com cinco repetições. No dia 2 de novembro 2017, após a colheita da cevada ocorreu a semeadura da soja (BRASMAX LANÇA-IPRO 58I60). A semeadura e fertilização na linha foi realizada com uma semeadora/adubadora, com linhas espaçadas em 0,45 m. A população final de plantas foi de 280 mil plantas ha-1 . Quando a cultura da soja atingiu a maturação fisiológica, três plantas em três linhas de cultivo (9 plantas) tiveram a altura total e altura da inserção da primeira vagem mensuradas. Em cada parcela, colheu-se 1,35 m2. Os componentes produtivos avaliados foram número de vagens, o peso de mil grão (PMG) e a produtividade da cultura. Os dados do experimento foram submetidos à análise de variância e, quando necessário, foram comparados pelo teste Tukey a 5% de probabilidade de erro com o auxílio do programa Statistix 10.0. Nenhum dos tratamentos (C+S, RE, T) influenciou significativamente os parâmetros apresentados avaliados. Para os tratamentos C+S, RE e T, o número médio de vagens por planta foi de 47, 45 e 46; o número total de grãos por planta foi 106, 98, 100 g; o peso de mil grãos foi 177, 179, 173g; e a produtividade foi de 4983, 4812, 5044 kg ha-1, respectivamente. Esses resultados mostram que a adubação antecipada em solos com sistema plantio direto consolidado (PD) e com níveis de fertilidade alto não é capaz de trazer nenhum efeito significativo nos componentes de rendimento da cultura da soja. O PD proporciona benefícios na qualidade biológica, química e física do solo, resultante do aporte dos resíduos provenientes da rotação de culturas. Tais benefícios, fazem com que o solo apresente uma maior retenção de água e uma melhor distribuição dos nutrientes no perfil, estimulando assim o desenvolvimento radicular da planta. Esses dados corroboram com Lana et al (2003), que verificaram que a adubação fosfatada e potássica antecipada em cinco meses antes da semeadura da soja não influenciou a produtividade da mesma durante o ano agrícola. SEGATELLI (2006) também observou que a antecipação total ou parcial da adubação da cultura da soja para a cultura antecessora (Eleusine coracana – campim pé-de-galinha), não reduz a produtividade. Segundo MATOS et al. (2006), o sistema de antecipação da adubação da cultura da soja é viável, reduzindo o número de operações, os custos operacionais totais, o que possibilita o aumento da receita liquida quando comparada ao sistema tradicional de adubação. Concluiu-se que a adubação antecipada da soja em um sistema plantio direto em solo com nível de fertilidade alto não influenciou os componentes de produtividade da cultura, reduzindo o custo de operação e incrementando a lucratividade da lavoura. Todavia, o sistema solo-planta-clima é bastante dinâmico, o que demanda condução de experimentos de longa duração sobre este tema.\n\n\nPalavras chave:\nProdutividade; Lucratividade; Operações agrícolas\n\n\nPôster\nIndisponível \n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "trabalho_pos/resumos/contexto_2018/arthur/trab1.html",
    "href": "trabalho_pos/resumos/contexto_2018/arthur/trab1.html",
    "title": "VIII Contextos e Conceitos",
    "section": "",
    "text": "Resumo\nA cultura do milho (Zea mays) é muito responsiva a adubação nitrogenada pelo fato de ser uma gramínea e não possuir a capacidade de realizar simbiose com bactérias fixadoras de nitrogênio (N). Este nutriente faz parte da composição da clorofila, influenciando diretamente a capacidade fotossintética das plantas. A adubação nitrogenada é um fator importante na composição da produtividade da cultura e tem um custo elevado. Resíduos industriais que possuem N em sua composição são uma alternativa para substituir ou complementar a adubação mineral. Um exemplo destes resíduos é o líquido de quarta (L4) obtido como no processamento das vísceras de suínos para produção de heparina. A heparina é um medicamento anticoagulante. O L4 contém, em média, teores consideráveis de nitrogênio – N (1,13%), potássio – K (0,08%) e fósforo – P (0,16%), que pode ser utilizado como fonte complementar de N para as culturas. O trabalho teve como objetivo avaliar o teor de clorofila e a produtividade da cultura do milho que recebeu o L4 como única fonte de N durante seu desenvolvimento. O experimento foi conduzido na área experimental do Instituto Federal do Paraná, no Campus Palmas, e consistiu na fertilização da cultura do milho com diferentes doses do L4. Cinco doses de L4 foram aplicadas anteriormente (dois dias) à semeadura da cultura: 0 m3 ha-1 ; 10 m3 ha-1 ; 20 m3 ha-1 ; 40 m3 ha-1 e 60 m3 ha-1 O delineamento experimental foi de blocos ao acaso com 4 repetições. Na semeadura do milho (Dow 2a620pw), também foi adicionado adubação de base de 160 kg ha-1 do formulado NPK 09-33-12, em todos os tratamentos. Na fase de pendoamento, os valores de Índice de Clorofila Falker (ICF) foram medidos em 15 plantas (15 leituras) por parcela com auxílio de um clorofilômetro clorofiLOG, marca Falker. Os teores de clorofila A (CA=12,8 + 1,9 ICFa), B (CB=0,9 + 0,5 ICFb) e Total (CA=13,8 + 2,4 ICFt) foram estimados pelas equações propostas por Vargas et al. (2012). Após a maturação fisiológica da cultura, o milho foi colhido manualmente, a palha das espigas foram retiradas e as espigas com grãos foram secas em estufa a 60°C por 48 horas. Após a secagem, as espigas foram debulhadas e os grãos pesados com umidade entre 14% e 20%, estimando a produtividade da lavoura sob efeito das doses de L4. Os dados foram submetidos à análise de variância e, quando significativos (p&lt;0,05), análise de regressão com auxílio do programa Estatistix 10.0. Os teores de clorofila A variaram de 58,65 a 87,16 µg g-1, clorofila B de 4,08 a 10,67µg g-1 e clorofila total de 86,96 a 154,62 µg g-1 e foram significativamente influenciados pelas doses de L4 aplicadas. O efeito das doses de L4 no aumento do teor de clorofila nas folhas foi observado até as doses de 42 m3 ha~-1^ para a clorofila A, B e total. O aumento nos teores de clorofila pode ser explicado pela disponibilidade de N ofertada pelo resíduo. Argenta et al. (2000) obteve correlações significativas entre os teores de N absorvido pela planta e o teor de clorofila. A diminuição do teor de clorofila na dose de 60 m3 ha-1 pode estar relacionada ao acúmulo de nitrato na planta, o qual não é associado a molécula de clorofila e não é mensurado pelo clorofilômetro (Dwyer et al., 1994). Além disso, o excesso de N faz a planta ter maior crescimento e diminuir a concentração de clorofila por área foliar. Outra implicação é a baixa precisão que o clorofilômetro pode apresentar quando os níveis de N estão elevados (Argenta et al., 2001). A produtividade do milho variou de 3429 kg ha-1 (0 m3 ha-1) a 12006 kg ha-1 (60 m3 ha-1), sendo influenciada pelas doses de L4 aplicadas. A máxima eficiência técnica foi estimada para a dose de 68 m3 ha-1. A baixa dose de adubação na base favoreceu a resposta da cultura às doses crescentes de resíduo industrial, visto que o líquido fornece quantidades de N, P, e K. Observou-se uma correlação positiva (p&lt;0,01) entre os teores de clorofila e o rendimento de grãos. O maior acúmulo de N proporcionou aumentou do número e do tamanho das folhas, as quais tiveram uma produção de fotoassimilados maior, que contribuíram para o incremento na produtividade (Soares, 2003). Vargas et al, (2012) observaram que o teor de clorofila mensurado em diferentes estádios de desenvolvimento do milho (12 – 15 folhas expandidas, pendoamento e espigamento) também está ligado a produtividade da cultura. Conclui se que o uso do resíduo industrial como fonte de N pode complementar a adubação mineral, pois houve acréscimo dos teores de clorofila na folha e de produtividade da cultura. Todavia, outros estudos são necessários para verificar se o L4 não causa efeitos negativos na dinâmica química, física e microbiológica do solo.\n\n\nPalavras chave:\nFotossíntese; Nitrogênio; Biofertilizantes.\n\n\nPôster\nIndisponível \n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "trabalho_pos/resumos/sbcs_2023/suane/trab1.html",
    "href": "trabalho_pos/resumos/sbcs_2023/suane/trab1.html",
    "title": "XXIII CLACS | XXXVIII CBCS",
    "section": "",
    "text": "Resumo\nOs térmitas são organismos representantes da macrofauna edáfica e conhecidos pelo processo de bioturbação do solo durante a construção de estruturas que permitem sua locomoção e sobrevivência no ambiente edáfico. A ação dos térmitas em mudar as características dos solos durante a construção de seus termiteiros tem sido estudada, mas ainda necessita ser melhor compreendida, principalmente no continente americano. O estudo pressupôs que os térmitas atuam seletivamente sobre os materiais do solo, durante a construção dos termiteiros, e objetivou avaliar diferenças e/ou similaridades relativas às frações areia e argila do solo e do termiteiro. Para tanto, foram amostrados um termiteiro e o solo adjacente em seis locais de cinco estados brasileiros. Nos materiais, foram realizadas análises sedimentológicas da fração areia e mineralógicas por difratometria de raios X, suscetibilidade magnética e dissoluções seletivas dos óxidos de ferro. A sedimentologia da fração areia indicou que os térmitas foram seletivos por partículas de areia de menor tamanho em solos com textura arenosa. Na maioria dos locais, os térmitas concentraram Fe e Al dos óxidos de ferro pedogênicos e Fe de formas de baixa cristalinidade. A suscetibilidade magnética não indicou uma tendência dominante dos minerais magnéticos entre solo e termiteiro. A difratometria de raios x da fração argila indicou que os térmitas não alteraram a mineralogia de solos altamente intemperizados com dominância de caulinita, gibbsita e óxidos de ferro, além de mostrar que esses organismos foram seletivos para partículas de tamanho argila nos solos arenosos.\n\n\nPalavras chave:\nMacrofauna; Mineralogia; Difração de raios X; Sedimentologia da areia\n\n\nPôster\nIndisponível \n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "trabalho_pos/resumos/sbcs_2023/kayn/trab1.html",
    "href": "trabalho_pos/resumos/sbcs_2023/kayn/trab1.html",
    "title": "XXIII CLACS | XXXVIII CBCS",
    "section": "",
    "text": "Resumo\nAs atuais técnicas de fertilização fosfatada promovem o aumento da concentração de P nos primeiros centímetros de solo, limitando a distribuição vertical do nutriente no perfil de solo. As estratégias de aplicação da adubação de correção e manutenção de P podem alterar a sua distribuição e a disponibilidade. O objetivo deste estudo foi avaliar diferentes estratégias de aplicação de P e seu efeito na distribuição e disponibilidade vertical do nutriente. O experimento foi realizado em Palmas, Paraná, Brasil, sobre um Latossolo Bruno sob campo nativo. Cinco forma de aplicação de P foram testadas: controle (C), correção e manutenção em superfície (S), correção e manutenção em linha (L), correção incorporada e manutenção em superfície (IS) e correção incorporada e manutenção em linha (IL). A adubação de P foi realizada com a aplicação de superfosfato simples (160 kg P2O5 ha-1 em correção; 72 kg P2O5 ha-1 em manutenção). Seis meses após a aplicação dos tratamentos, amostras de solo foram coletadas nas camadas 0-5, 5-10, 10-15, 15-20, 20-25, 25-30 e 30-40 cm de profundidade. O P extraído do solo por solução Mehlich-I foi determinado por espectrofotometria de absorção molecular. O teor de P disponível, até os 10 cm, foi influenciado pela interação da profundidade e da forma de aplicação do P. Os tratamentos S e IS apresentaram os maiores teores de P nos primeiros 5 cm de solo em relação a IL e C, mas os valores reduziram na segunda camada avaliada (5-10cm). A aplicação de P em L melhorou a disponibilidade do nutriente na profundidade 0-5 e 5-10 cm em comparação à C. Ainda, no L o teor de P foi similar nas duas primeiras camadas, demonstrando maior homogeneidade na distribuição vertical do P. A estratégia de aplicação da adubação de correção e manutenção afeta a disponibilidade e a distribuição vertical do P. Apesar do aumento da disponibilidade de P em 0-5 cm, S e IS não melhoram distribuição vertical. L apresenta melhor disponibilidade e distribuição de P em relação a C.\n\n\nPalavras chave:\nFertilização; Disponibilidade de P; P em profundidade\n\n\nPôster\nIndisponível \n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "trabalho_pos/resumos/sbcs_2019/gustavo/trab1.html",
    "href": "trabalho_pos/resumos/sbcs_2019/gustavo/trab1.html",
    "title": "XXXVII - Congresso Brasileiro de Ciência do Solo",
    "section": "",
    "text": "Resumo\nIntrodução – O emprego de resíduos industriais na agricultura pode ser uma alternativa para o descarte desses subprodutos. A produção de heparina, por meio das vísceras de suínos, gera um resíduo industrial (RI) com alto teor de Na que está sendo utilizado como fertilizantes por muitos agricultores. O objetivo deste trabalho foi avaliar atributos químicos e microbiológicos de um solo que recebeu o RI da produção de heparina. Material e Métodos – O experimento foi conduzido no Laboratório de Solos do IFPR - Campus Palmas com uma amostra da camada 0-20 de um Latossolo. O solo foi acondicionado em recipientes hermeticamente fechados, onde aplicou-se os tratamentos 0, 10, 20, 40 e 60 m3 de RI ha-1 e determinou-se a respiração basal do solo. Após o período de incubação das amostras (47 dias), os valores de pH em água, condutividade elétrica, carbono orgânico (Corg) e os teores de P, K e Na foram determinados. Os resultados foram submetidos à análise de variância (p&lt;0,05) e, quando significativa, a análise de regressão foi realizada. Resultados e Discussão – O teor de P não apresentou diferenças significativas, enquanto que o teor de Na, K e a respiração basal do solo aumentaram linearmente com as doses do RI. A grande quantidade de Na e K na composição do RI foi responsável pelo aumento desses elementos no solo e, consequentemente, influenciaram positivamente a condutividade elétrica. O pH e o teor de Corg do solo variaram de forma quadrática – as doses intermediárias diminuíram os valores observados. O RI ocasionou aumento da taxa respiratória, por fornecer nutrientes prontamente disponíveis. Isso levou à ativação microbiológica do solo e redução do Corg. O aumento da taxa de decomposição da matéria orgânica tem como resultado a liberação de CO2 e íons NO3- e H+, sendo fonte de acidez no solo. Isso pode ser observado pela redução nos valores de pH. Conclusões – O uso indiscriminado do RI estudado pode ocasionar problemas de salinidade no solo e diminuir os teores de Corg pelo aumento da atividade microbiológica.\n\n\nPalavras chave:\nResíduo industrial; Microbiologia\n\n\nPôster\n\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "trabalho_pos/resumos/cacs_2022/gustavo/trab1.html",
    "href": "trabalho_pos/resumos/cacs_2022/gustavo/trab1.html",
    "title": "XXVIII - Congreso Argentino de la Ciencia del Suelo",
    "section": "",
    "text": "Resumo\nA heparina é o medicamento de ação anticoagulante mais utilizado na atualidade. A extração da heparina ocorre ao processar mucosa intestinal de suínos, processo esse que gera uma grande quantidade de resíduo orgânico-salino (RIS). Embora tenha potencial fertilizante, o RIS possui alto teor de sódio (Na=1400 mg L-1) e, quando disposto em solos pode levar a problemas na física do solo através da dispersão das partículas. O objetivo deste estudo foi avaliar o efeito de doses do RIS na concentração de Na, na percentagem de Na trocável (PST) e na dispersão da fração argila em um Latossolo. O experimento consistiu na aplicação anual de cinco doses do RIS (0, 10, 20, 40 e 60 m3 ha-1) como única fonte de nutrientes para as culturas. Amostras de solo foram coletadas em agosto de 2020, três anos após a primeira aplicação e oito meses desde a última aplicação, em seis camadas de solo (0-5, 5-10, 10-20, 20-30, 30-40, 40-60 cm). As análises foram realizadas na fração terra fina seca ao ar (\\(\\theta&lt;2mm\\)). O teor de Na disponível foi determinado por espectrofotometria de chama. Com o teor de Na e a CTC foi calculada a PST. Para avaliar a dispersão das partículas foi determinada a relação da argila fina / argila total por centrifugação. Todos os parâmetros mostraram interação entre as doses de RIS e a camada avaliada. Foi observado aumento do teor de Na bem como da PST com o aumento da dose para todas as camadas, exceto para 5-10 cm. A alta concentração de Na no RIS foi responsável por aumentar o teor desse elemento no solo, mesmo oito meses depois da última aplicação. Nas doses mais altas (40 e 60 m3 ha-1) foi observado aumento do Na em profundidade, devido à alta mobilidade desse elemento e sua consequente lixiviação. Embora tenha aumentado, a PST de maior valor foi 1,2%, observada na camada superficial na dose de 60 m3 ha-1, a qual é inferior aos 6% a partir do qual começam a ocorrer efeitos de toxidade para as plantas. A relação argila fina / argila total aumentou somente nas camadas mais superficiais (0-5, 5-10 e 10-20 cm) onde houve maior contado do RIS. Porém o aumento da relação argila fina / argila total mostra que embora o Na seja facilmente lixiviado, há um processo inicial de dispersão das partículas mais reativas do solo pelo contado com o Na. Embora esteja ocorrendo um processo inicial de dispersão, não foi constatado movimento de partículas no perfil. O uso do RIS como fonte de nutriente em um Latossolo causa mudanças no complexo sortivo do solo, além de desencadear problemas iniciais na física do solo, por meio da dispersão das partículas.\n\n\nPalavras chave:\nResíduo salino; Sódio; Dispersão do solo\n\n\nPôster\n\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "trabalho_pos/resumos/rsbcs_2018/gustavo/trab1.html",
    "href": "trabalho_pos/resumos/rsbcs_2018/gustavo/trab1.html",
    "title": "XII - Reunião Sul Brasileira de Ciência do Solo",
    "section": "",
    "text": "Resumo\n\n\n\nPôster\n\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "curiculo/teste_curi.html",
    "href": "curiculo/teste_curi.html",
    "title": "teste_curi",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "curiculo/teste_curi.html#quarto",
    "href": "curiculo/teste_curi.html#quarto",
    "title": "teste_curi",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "curiculo/guga2/guga2.html",
    "href": "curiculo/guga2/guga2.html",
    "title": "Untitled",
    "section": "",
    "text": "Resumo\nSou Gustavo Frosi, engenheiro agrônomo e mestre em Ciência do Solo, com uma trajetória acadêmica marcada pela busca constante por conhecimento. Natural de Ouro Verde - Santa Catarina, atualmente resido em Porto Alegre - Rio Grande do Sul. Desde a iniciação científica, dediquei-me ao estudo do solo, participando de variados experimentos de campo e laboratório. No mestrado, concentrei-me nas propriedades químicas e físicas do solo e o impacto do uso de resíduos. Atualmente, no doutorado, meu foco é o potássio e como otimizar sua recomendação para uso mais eficiente. Minha experiência com análise de dados começou cedo e se desenvolveu em uma paixão, resultando em amplo conhecimento em manipulação e visualização de dados, especialmente com o R.\n\n\nExperiência\n\n\n\nEducação\n\n\n\nProjetos\nSee my github profile for a comprehensive list of open source projects.\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "curiculo/Guga/Guga.html",
    "href": "curiculo/Guga/Guga.html",
    "title": "R Developer",
    "section": "",
    "text": "Experience\n\n\n\nEducation\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "curiculo/guga2/template-cover-letter.html",
    "href": "curiculo/guga2/template-cover-letter.html",
    "title": "Motivation letter",
    "section": "",
    "text": "Dear big boss,\nThis is my first paragraph. I’m super interested in the job.\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.\nKind regards,\nDavid\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "projetos/2023-11-01 disciplina de R para ufrgs solos/index.html#cronograma",
    "href": "projetos/2023-11-01 disciplina de R para ufrgs solos/index.html#cronograma",
    "title": "R para ciência do solo",
    "section": "",
    "text": "Um total de nove aulas foram produzidas (Tabela 1) e ministradas ao longo de pouco mais de um mês. O conteúdo programático começou pelos fundamentos, considerando que alguns alunos nunca haviam tido contato prévio com a ferramenta. Assim, iniciamos com uma introdução ao ambiente, abordando os conceitos mais básicos do funcionamento de uma linguagem de programação. Na segunda etapa, o foco foi direcionado para a análise de dados, incluindo procedimentos de manipulação e visualização de dados, além da aplicação dos principais testes estatísticos. Por fim, a última etapa consistiu em uma breve explanação sobre análise multivariada e na criação de relatórios com o R.\n\n\n\n\nTabela 1: Cronograma das aulas do curso\n\n\n\n\n\n\n\n\nAula\nTópicos\n\n\n\n\n1\nApresentação da disciplina, lógica de programação para não programadores, histórico do R, aplicação à Ciência do Solo, instalação de softwares\n\n\n2\nInterface do R, sintaxe básica, operadores, objetos e classes de objetos no R\n\n\n3\nOperações matemáticas, estruturas de repetição e seleção, funções, organização de planilhas\n\n\n4\nImportação de dados, organização, filtro, seleção, transformação de variáveis, exportação de dados\n\n\n5\nGráficos no R com ggplot2, gramática de gráficos, gráficos de pontos, barras, linhas e composição\n\n\n6\nEstatística descritiva, ANOVA, testes de comparação de médias\n\n\n7\nModelos mistos, correlação e regressões\n\n\n8\nTestes não paramétricos\n\n\n9\nPCA, análise discriminante, relatórios automáticos"
  },
  {
    "objectID": "projetos/2023-11-01 disciplina de R para ufrgs solos/index.html#a-experiência",
    "href": "projetos/2023-11-01 disciplina de R para ufrgs solos/index.html#a-experiência",
    "title": "R para ciência do solo",
    "section": "",
    "text": "Para mim, foi uma oportunidade incrível participar desta disciplina. Não apenas pela dinâmica de estruturar, organizar e conduzir as atividades, mas também por ensinar algo que terá um impacto direto no trabalho dos meus colegas e amigos da pós-graduação. É claro que, assim como outras, esta disciplina representa apenas um ponto de partida; muito estudo ainda será necessário no futuro.\nFoi fascinante observar como, ao longo do tempo, os alunos foram capazes de realizar todas as tarefas propostas e de avançar de forma autônoma, mesmo após o término da disciplina. Isso é ainda mais relevante considerando que uma ferramenta como a programação não é algo convencional para a maioria das pessoas, mesmo dentro da academia.\nQuero deixar registrado meu agradecimento ao PPGCS por aceitar a iniciativa, ao professor Tales Tiecher pela provocação, incentivo e apoio ao longo desse processo, e ao Gustavo Pesini por colaborar comigo e compartilhar a responsabilidade para que tudo ocorresse conforme o planejado."
  },
  {
    "objectID": "projetos/2023-11-01_R_UFRGS/index.html",
    "href": "projetos/2023-11-01_R_UFRGS/index.html",
    "title": "R para ciência do solo",
    "section": "",
    "text": "No ano de 2023, foi dado um importante passo na Pós-Graduação em Ciência do Solo da UFRGS: a criação da primeira disciplina totalmente voltada ao ensino e aprendizado da linguagem de programação R. O mais entusiasmante foi poder contribuir com todo esse processo.\nPor iniciativa do professor Tales Tiecher, eu, junto com Gustavo Pesini, construímos uma série de aulas e exercícios práticos, com foco na manipulação de dados, análise e visualização desses dados, voltados para o estudo em Ciência do Solo. O principal objetivo da disciplina foi capacitar os alunos a desenvolverem suas próprias análises de dados utilizando os recursos da linguagem de programação R.\nLembro-me perfeitamente do dia em que o professor Tales fez a provocação sobre a criação de uma disciplina sobre o R. Eu, mais do que ansioso para compartilhar um pouco do que vinha aprendendo ao longo de alguns anos, aceitei na hora. Afinal de contas, trata-se de uma ferramenta muito versátil e extremamente útil na área acadêmica. Aos poucos, fomos dando forma a essa pequena ideia. Busquei a ajuda de alguém que, além de saber muito sobre R, é uma pessoa de confiança e dedicação: Gustavo Pesini. Em pouco tempo, já estávamos com o cronograma e as aulas estruturadas. No dia 19/10/2023, iniciamos a jornada de ensinar (e aprender) a linguagem de programação R com nossos colegas de pós-graduação (Figura 1).\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigura 1: Primeira aula da disciplina de R para Ciência do Solo da UFRGS\n\n\n\n\n\n\n\nUm total de nove aulas foram produzidas (Tabela 1) e ministradas ao longo de pouco mais de um mês. O conteúdo programático começou pelos fundamentos, considerando que alguns alunos nunca haviam tido contato prévio com a ferramenta. Assim, iniciamos com uma introdução ao ambiente, abordando os conceitos mais básicos do funcionamento de uma linguagem de programação. Na segunda etapa, o foco foi direcionado para a análise de dados, incluindo procedimentos de manipulação e visualização de dados, além da aplicação dos principais testes estatísticos. Por fim, a última etapa consistiu em uma breve explanação sobre análise multivariada e na criação de relatórios com o R.\n\n\n\n\nTabela 1: Cronograma das aulas do curso\n\n\n\n\n\n\n\n\nAula\nTópicos\n\n\n\n\n1\nApresentação da disciplina, lógica de programação para não programadores, histórico do R, aplicação à Ciência do Solo, instalação de softwares\n\n\n2\nInterface do R, sintaxe básica, operadores, objetos e classes de objetos no R\n\n\n3\nOperações matemáticas, estruturas de repetição e seleção, funções, organização de planilhas\n\n\n4\nImportação de dados, organização, filtro, seleção, transformação de variáveis, exportação de dados\n\n\n5\nGráficos no R com ggplot2, gramática de gráficos, gráficos de pontos, barras, linhas e composição\n\n\n6\nEstatística descritiva, ANOVA, testes de comparação de médias\n\n\n7\nModelos mistos, correlação e regressões\n\n\n8\nTestes não paramétricos\n\n\n9\nPCA, análise discriminante, relatórios automáticos\n\n\n\n\n\n\n\n\n\n\n\n\nPara mim, foi uma oportunidade incrível participar desta disciplina. Não apenas pela dinâmica de estruturar, organizar e conduzir as atividades, mas também por ensinar algo que terá um impacto direto no trabalho dos meus colegas e amigos da pós-graduação. É claro que, assim como outras, esta disciplina representa apenas um ponto de partida; muito estudo ainda será necessário no futuro.\nFoi fascinante observar como, ao longo do tempo, os alunos foram capazes de realizar todas as tarefas propostas e de avançar de forma autônoma, mesmo após o término da disciplina. Isso é ainda mais relevante considerando que uma ferramenta como a programação não é algo convencional para a maioria das pessoas, mesmo dentro da academia.\nQuero deixar registrado meu agradecimento ao PPGCS por aceitar a iniciativa, ao professor Tales Tiecher pela provocação, incentivo e apoio ao longo desse processo, e ao Gustavo Pesini por colaborar comigo e compartilhar a responsabilidade para que tudo ocorresse conforme o planejado.\n\n\n\n\nPara trazer um pouco das “vozes” e da vivência de quem participou do processo, fiz questão de perguntar a alguns dos envolvidos como foi a experiência e se houve benefícios pessoais.\nAbaixo estão os relatos não apenas das pessoas que viabilizaram e permitiram a realização da disciplina, mas também de quem se dispôs a aprender um pouco sobre a ferramenta.\n\nA disciplina “R Aplicado à Ciência do Solo”, organizada e ministrada com a participação do Doutorando Gustavo Frosi do PPGCS, foi um marco importante na formação e capacitação dos alunos. Ao longo do curso, foram atendidas as expectativas quanto à construção e condução do conteúdo, que proporcionou uma sólida base no uso do software R como ferramenta essencial para análise e visualização de dados na Ciência do Solo. A disciplina destacou a relevância do aprendizado de ferramentas computacionais, independentemente da área, mostrando como elas podem otimizar o trabalho de análise de dados e contribuir para o avanço na interpretação e apresentação de dados. A contribuição dessa disciplina ao PPGCS foi imensa, pois além de enriquecer o currículo, ofereceu aos alunos uma valiosa oportunidade de aprimoramento, capacitando-os para desafios futuros na área científica e profissional. A experiência proporcionada foi um grande diferencial na formação dos alunos do PPGCS da UFGRS. - Tales Tiecher (Professor de Química do Solo do Departamento de Solos da Faculdade de Agronomia da UFRGS)\n\n\nSão perguntas difíceis. Por que eu topei fazer disciplina aquela vez? Eu acho que foi mais por um desafio. Porque quando você tem que passar informação para alguém, você precisa primeiro saber sobre o que tu estás falando. Não necessariamente você precisa dominar aquele assunto, mas entender do que tu estás querendo dizer. Então, acho que foi mais por isso mesmo, sabe? Mais por um desafio. Porque se eu tenho que falar para as pessoas sobre regressão, eu vou atrás de aprender sobre o que é regressão e isso foi importante porque depois deu para ver como resultado que eu tive de ir atrás e buscar material, de buscar um monte de coisa que foi bem bacana. Então, acho que mais por isso. Eu acho que a importância para o programa é bastante grande, visto que a gente usa muito esse tipo de abordagem para avaliar dados. Nós trabalhamos muito com a experimentação agrícola, que envolve esse tipo de análise, que com essas ferramentas se dá para fazer esse tipo de análise de forma rápida, facilitada, automatizada, e que é importante para nós aqui como estudantes na pós-graduação. Acho que seria isso. E, para mim, obviamente, foi algo bastante importante, porque, claro, quando você desafia a fazer um trabalho, tu tens que saber sobre o que tu tá falando, voltando lá no início do que eu estive falando. Mas, com certeza, eu aprendi bastante coisa com as tuas aulas, como aluno também, já que eu estava matriculado e passando algumas coisas também. Então foi mais ou menos isso. - Gustavo Pesini (Mestrando em Ciência do Solo - UFRGS)\n\n\nFazer o curso de R desenvolvido no Programa de Pós-Graduação em Ciência do Solo foi uma experiência transformadora para mim. Eu comecei do zero, sem nenhum conhecimento na área, e com o curso consegui aprender a organizar e analisar dados, além de criar gráficos de forma prática. O que mais gostei foi como os conceitos foram explicados de maneira clara e acessível, o que me ajudou a entender temas que antes pareciam complexos. Esse aprendizado também complementou muito bem os conteúdos da disciplina de estatística que estou estudando. Recomendo o curso do R, principalmente às pessoas que, estão iniciando na análise de dados e querem construir uma base sólida. - Alder Duarte (Doutorando em Ciência do Solo - UFRGS)\n\n\nMinha experiência no curso de R foi muito desafiadora, pois nunca havia trabalhado com programação, e ainda mais considerando análises estatísticas. Assim, foi muito gratificante aprender e descobrir que, com a programação, eu poderia obter uma análise completa sobre meu mundo de dados – e falo “um mundo” porque há muita coisa. A abordagem por parte da equipe que ofereceu o curso facilitou muito meu trabalho, permitindo otimizar meu tempo. - Anahi Ferreira (Mestranda em Ciência do Solo - UFRGS)\n\n\nTive muita satisfação com a disciplina de R. O conteúdo foi relevante e bem estruturado, desde conceitos básicos até aplicações práticas. Isso me permitiu aprender a criar scripts tanto análise dos dados quanto na criação de gráficos para minha pesquisa. Além disso, a introdução de tópicos sobre a visualização dos dados, com o uso do pacote ggplot2, foi uma ótima forma para ver as possibilidades de aplicação do R. Os professores demonstraram grande domínio do R e seus pacotes, sempre disposto a esclarecer dúvidas e oferecer exemplos práticos relacionados a nossa área de pesquisa. No geral, foi uma experiência muito positiva e enriquecedora. Me permitiu ter contato com uma ferramenta muito boa e que será de muita ajuda em meus trabalhos. Hoje, sem necessitar de auxílio do professor, já consigo criar meus próprios scripts para atender as minhas demandas. Agradeço pela oportunidade de participar dessa disciplina. - Kayn Eduardo (Mestrando em Ciência do Solo - UFRGS)\n\n\n\n\nÓbvio que uma parte analítica não poderia faltar!\nRealizei uma pequena análise dos relatos acima. O objetivo foi identificar, no conjunto total de textos, quais emoções foram transmitidas.\nSem muita enrolação, a Figura 2 apresenta as contagens totais de cada emoção. Observa-se que a maioria expressou frases com sentimentos positivos, o que reforça a relevância da disciplina.\n\n\n\n\n\n\n\n\nFigura 2: Emoções passadas pelos relatos da disciplina"
  },
  {
    "objectID": "projetos/2023-11-01_R_UFRGS/index.html#cronograma",
    "href": "projetos/2023-11-01_R_UFRGS/index.html#cronograma",
    "title": "R para ciência do solo",
    "section": "",
    "text": "Um total de nove aulas foram produzidas (Tabela 1) e ministradas ao longo de pouco mais de um mês. O conteúdo programático começou pelos fundamentos, considerando que alguns alunos nunca haviam tido contato prévio com a ferramenta. Assim, iniciamos com uma introdução ao ambiente, abordando os conceitos mais básicos do funcionamento de uma linguagem de programação. Na segunda etapa, o foco foi direcionado para a análise de dados, incluindo procedimentos de manipulação e visualização de dados, além da aplicação dos principais testes estatísticos. Por fim, a última etapa consistiu em uma breve explanação sobre análise multivariada e na criação de relatórios com o R.\n\n\n\n\nTabela 1: Cronograma das aulas do curso\n\n\n\n\n\n\n\n\nAula\nTópicos\n\n\n\n\n1\nApresentação da disciplina, lógica de programação para não programadores, histórico do R, aplicação à Ciência do Solo, instalação de softwares\n\n\n2\nInterface do R, sintaxe básica, operadores, objetos e classes de objetos no R\n\n\n3\nOperações matemáticas, estruturas de repetição e seleção, funções, organização de planilhas\n\n\n4\nImportação de dados, organização, filtro, seleção, transformação de variáveis, exportação de dados\n\n\n5\nGráficos no R com ggplot2, gramática de gráficos, gráficos de pontos, barras, linhas e composição\n\n\n6\nEstatística descritiva, ANOVA, testes de comparação de médias\n\n\n7\nModelos mistos, correlação e regressões\n\n\n8\nTestes não paramétricos\n\n\n9\nPCA, análise discriminante, relatórios automáticos"
  },
  {
    "objectID": "projetos/2023-11-01_R_UFRGS/index.html#a-experiência",
    "href": "projetos/2023-11-01_R_UFRGS/index.html#a-experiência",
    "title": "R para ciência do solo",
    "section": "",
    "text": "Para mim, foi uma oportunidade incrível participar desta disciplina. Não apenas pela dinâmica de estruturar, organizar e conduzir as atividades, mas também por ensinar algo que terá um impacto direto no trabalho dos meus colegas e amigos da pós-graduação. É claro que, assim como outras, esta disciplina representa apenas um ponto de partida; muito estudo ainda será necessário no futuro.\nFoi fascinante observar como, ao longo do tempo, os alunos foram capazes de realizar todas as tarefas propostas e de avançar de forma autônoma, mesmo após o término da disciplina. Isso é ainda mais relevante considerando que uma ferramenta como a programação não é algo convencional para a maioria das pessoas, mesmo dentro da academia.\nQuero deixar registrado meu agradecimento ao PPGCS por aceitar a iniciativa, ao professor Tales Tiecher pela provocação, incentivo e apoio ao longo desse processo, e ao Gustavo Pesini por colaborar comigo e compartilhar a responsabilidade para que tudo ocorresse conforme o planejado."
  }
]